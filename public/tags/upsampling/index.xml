<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Upsampling on Machine Learnig Py</title>
    <link>/tags/upsampling/</link>
    <description>Recent content in Upsampling on Machine Learnig Py</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>Will update soon (Mohit Sharma)</managingEditor>
    <webMaster>Will update soon (Mohit Sharma)</webMaster>
    <copyright>&amp;copy; Copyright by Machine Learning Py {year}, All Rights Reserved</copyright>
    <lastBuildDate>Sun, 15 Dec 2019 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/tags/upsampling/index.xml" rel="self" type="application/rss+xml" />
    
    
    
      
      <item>
        <title>SMOTE for dealing with imbalanced dataset</title>
        <link>/notes/smote-dealing-imbalanced-data/</link>
        <pubDate>Sun, 15 Dec 2019 00:00:00 +0000</pubDate>
        <author>Will update soon (Mohit Sharma)</author>
        <guid>/notes/smote-dealing-imbalanced-data/</guid>
        <description>It is generally not a good idea to train a Machine Learning algorithm when one of the class dominates the other. It is advisable to upsample the minority class or downsample the majority class. Synthetic Minority Over-sampling Technique (SMOTE) is one such algorithm that can be used to upsample the minority class.
When to use SMOTE Machine Learning algorithms find it challenging to learn the patterns if the examples from one of the classes are limited.</description>
      </item>
      
    
  </channel>
</rss>