[
{
	"uri": "/",
	"title": "",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/anomaly/",
	"title": "Anomaly",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories/clustering/",
	"title": "Clustering",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/cooks-distance/",
	"title": "Cooks Distance",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/dbscan/",
	"title": "DBSCAN",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/posts/outlier-anomaly-detection/",
	"title": "How to identify Anomalies/Outliers in Python",
	"tags": ["Python", "Outlier", "Anomaly", "Multivariate", "Univariate", "DBSCAN", "IsolationForest", "Cooks Distance"],
	"categories": [],
	"series": [],
	"description": "In this article, we discuss both univariate and multivariate outlier detection techniques with examples.",
	"content": "Introduction Data objects or points which exhibit very different behavior than the expectations are called as outliers or anomalies. They can indicate variability in the measurement, an error in the collection, a new point(due to some changes), or it could be true, which happens to be away from most of the observations.\n Detecting and treating outliers is an important part of data exploration.\n Different Methods For Detecting Outlier Before we dig into different methods which you can use to identify outliers, it is important to understand the different types of an outlier.\nTypes of outliers The outliers can be of two types:\n Univariate - An observation is termed as univariate outlier if we consider the distribution of only one feature. Multivariate - On the other hand, Multivariate outliers are found by considering n-dimensional space.  Example #1 - Univariate outlier detection using boxplots 1 2  import seaborn as sns\rsns.boxplot(x=boston[\u0026#39;ZN\u0026#39;])\r  In the above plot, the back dots represent outliers. These outliers are calculated based on the below-mentioned formula. Remember, the outliers can be on either side.\n(Higher side Outliers = Q3 + 1.5 * IQR )\n(Lower side Outliers = Q1 - 1.5 * IQR )\nThe IQR stands for Inter Quartile Range.\n(IQR = Q3 - Q1)\nHere - Q3 is the 75thand Q1 is 25thpercentile.\nExample #2 - Univariate outlier detection using Z-Score Z-score is a measure that helps us know how many standard deviations below or above the population mean a raw score is.\nZscore= \\frac{x - \\mu\\over \\sigma}\n1 2 3 4  from scipy.stats import zscore\rimport numpy as np\rz = np.abs(zscore(boston))\rprint(z)\r  1 2 3 4 5 6 7  [[0.41978194 0.28482986 1.2879095 ... 1.45900038 0.44105193 1.0755623 ]\r[0.41733926 0.48772236 0.59338101 ... 0.30309415 0.44105193 0.49243937]\r[0.41734159 0.48772236 0.59338101 ... 0.30309415 0.39642699 1.2087274 ]\r...\r[0.41344658 0.48772236 0.11573841 ... 1.17646583 0.44105193 0.98304761]\r[0.40776407 0.48772236 0.11573841 ... 1.17646583 0.4032249 0.86530163]\r[0.41500016 0.48772236 0.11573841 ... 1.17646583 0.44105193 0.66905833]]\r  From the above generated Z-scores, the observations which have got a score higher than 3 are the outliers.\n1 2  threshold = 3\rprint(np.where(z \u0026gt; 3))\r  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  (array([ 55, 56, 57, 102, 141, 142, 152, 154, 155, 160, 162, 163, 199,\r200, 201, 202, 203, 204, 208, 209, 210, 211, 212, 216, 218, 219,\r220, 221, 222, 225, 234, 236, 256, 257, 262, 269, 273, 274, 276,\r277, 282, 283, 283, 284, 347, 351, 352, 353, 353, 354, 355, 356,\r357, 358, 363, 364, 364, 365, 367, 369, 370, 372, 373, 374, 374,\r380, 398, 404, 405, 406, 410, 410, 411, 412, 412, 414, 414, 415,\r416, 418, 418, 419, 423, 424, 425, 426, 427, 427, 429, 431, 436,\r437, 438, 445, 450, 454, 455, 456, 457, 466], dtype=int64),\rarray([ 1, 1, 1, 11, 12, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1,\r1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 1, 5,\r5, 3, 3, 3, 3, 3, 3, 1, 3, 1, 1, 7, 7, 1, 7, 7, 7,\r3, 3, 3, 3, 3, 5, 5, 5, 3, 3, 3, 12, 5, 12, 0, 0, 0,\r0, 5, 0, 11, 11, 11, 12, 0, 12, 11, 11, 0, 11, 11, 11, 11, 11,\r11, 0, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11],\rdtype=int64))\r  The first array contains the row numbers where the values were higher than the threshold( set at 3 in our case). The second array contains the column numbers.\nExample #3 - Multivariate outlier detection using DBSCAN DBSCAN(Density-based spatial clustering of applications with noise) is a density-based clustering algorithm. The algorithm works on the intuition that clusters are nothing but a collection of similar points which are present as dense regions in the data space.\nDBSCAN Parameters Explained   eps: It is the distance between two data points. If the distance between two points is closer or equal to the eps value than these two points are considered normal points or neighbors. If the distance between two points is greater than the specified eps value than that point is considered as noise. A smaller eps value results in too many outliers. A lager eps value than different clusters will get merged, and most of the data points will be in the same clusters.\n  min_samples: Represents the number of points to be considered as core data points around a specific point. If the data is dense, then it is advised to select a larger number of min_samples. The min_samples can also be derived using the following formula:\n  min_samples = D + 1\nHere, D is the number of Dimensions(features) in a dataset.\nHow DBSCAN algorithm works? The algorithm works on the premise of multivariate clustering. It looks for data points that are geometrically closer to each other. To understand the algorithm, you should first understand the following terms.\n  Core Points - These are the points that have min_samples within eps distance.\n  Border Points - These are the points that are in the range of eps but have less than min_samples points.\n  Noise - All other points which are neigther Border Points nor are Core Points.\n  The algorithm can be abstracted in the following steps:\n  Start with a random point; find neighboring points that are within the eps radius. If these nearby points exceed or equal the min_sample then they care marked as core points.\n  Check if the core point has been assigned to a cluster, if not, create a new group.\n  Recursively find density connected points and assign them to the same cluster as a core point. *The above process is called chaining. A point x and y are said to be close enough if there is a point z, which has enough number of points within eps distance. So basically, if y is a neighbor of z, z is a neighbor of x.\n  Like this iterate over the remaining data points. The points that do not get assigned to a cluster are considered as noise or outliers.\n  Working Example Let us load the Python packages, which we will be using for our example.\n1 2 3 4 5  import numpy as np\rimport pandas as pd\rfrom sklearn.datasets import load_iris\rfrom sklearn.cluster import DBSCAN\rfrom sklearn.preprocessing import StandardScaler\r  Loading and preparing iris dataset for the example.\n If variables are on different scales, then ensure that you bring them on the same scale. If in doubt, it is advised to go ahead with the scaling.\n 1 2 3 4 5 6 7 8 9 10 11 12 13  iris = load_iris()\rX_train = iris.data\rY_train = iris.target\rcolumns = iris.feature_names\r#Loading iris dataset\r X_train = pd.DataFrame(X_train)\rX_train.columns = columns\r# Adding column names\r scaler = StandardScaler().fit(X_train)\rX_train = scaler.transform(X_train)\r# Scaling - Bringing data points on same scale\r   Now that the dataset is all prepared let's use DBSCAN to identify the outliers in the dataset.\n1 2 3 4 5 6 7 8 9 10  clustering = DBSCAN(eps=0.5, min_samples=5).fit(X_train)\r# Fitting the DBSCAN model\r labels = clustering.labels_\r# Abstracting the data points\r core_points = np.zeros_like(labels, dtype = bool)\rcore_points[clustering.core_sample_indices_] = True\r# Adding False for non core points\r n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\rn_noise_ = list(labels).count(-1)\r# counting the number of outliers\r   Out of 150 data points, around 34 points have been identified as outlier\nHow to visualize the DBSCAN output We will be using matplotlib to plot the DBSCAN output. The points which are represented by small solid dots are the outliers.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  import matplotlib.pyplot as plt\rplt.figure(figsize=(15,8))\runique_labels = set(labels)\rcolors = [plt.cm.Spectral(each)\rfor each in np.linspace(0, 1, len(unique_labels))]\rfor k, col in zip(unique_labels, colors):\rif k == -1:\r# Black used for noise.\r col = [0, 0, 0, 1]\rclass_member_mask = (labels == k)\rxy = X_train[class_member_mask \u0026amp; core_samples]\rplt.plot(xy[:, 0], xy[:, 1], \u0026#39;o\u0026#39;, markerfacecolor=tuple(col),\rmarkeredgecolor=\u0026#39;k\u0026#39;, markersize=14)\rxy = X_train[class_member_mask \u0026amp; ~core_samples]\rplt.plot(xy[:, 0], xy[:, 1], \u0026#39;o\u0026#39;, markerfacecolor=tuple(col),\rmarkeredgecolor=\u0026#39;k\u0026#39;, markersize=6)\rplt.title(\u0026#39;Estimated number of clusters: %d\u0026#39; % n_clusters_)\rplt.show()\r  Cooks distance captures the change in the regression output by removing individual data points. The results will change drastically if an influential point is removed. Cook's distance measures the effect of an individual data point on all of the fitted values. The cook's distance statistics is calculated as given below:\nIF THE Di$\\ge$ 1 THE VALUE IS CONSIDERED EXTREME AND IS TREATED AS AN OUTLIER\nWorking Example 1 2 3 4 5 6 7 8 9 10  from yellowbrick.regressor import CooksDistance\rfrom yellowbrick.datasets import load_concrete\r# Load the regression dataset\r X, y = load_concrete()\r# Instantiate and fit the model\r cd = CooksDistance()\rcd.fit(X_train, Y_train)\rcd.show()\r  The example is borrowed from yellobrick documentation.\n Cook's Distance is not effective in detecting a group of outliers. Because if you remove one value from the cluster of an outlier, the effect on the model will not be much.\n How does the isolation forest works To isolate an observation, the algorithm uses a random feature and then splits the values between the minimum and the maximum value of the selected feature. The intuition behind the algorithm is very simple: isolating an anomaly should be easier as only a few conditions should be required to separate such cases from the normal observations. On the other hand, more conditions are required to isolate normal cases.\nThe isolation forest first constructs random decision trees or isolation trees and repeats the process several times. Then, the average path length is calculated and normalized.\n The Isolation Forest algorithm shows strong promise as the other Machine Learning methods tend to work fine only in case the patterns are balanced, meaning the dataset contains the equal amount of normal and bad values in the dataset.\n Working Example 1 2 3 4 5 6 7 8 9 10 11 12  from yellowbrick.datasets import load_concrete\rfrom sklearn.ensemble import IsolationForest\rX_train, Y_train = load_concrete()\r# Loading the concrete dataset\r isolationTree = IsolationForest(random_state = 0).fit(X_train)\rpred_outliers_scores = isolationTree.decision_function(X_train)\r# Building isolationforest model to identify anomalies\r plt.figure(figsize=(20, 10))\rplt.hist(pred_outliers_scores, bins = 50)\r#Plotting and visualising the data points\r   So we see that there are clusters under -0.04. Thus, observation with the average score for path lengths shorter than -0.04 will be considered as anomalies or outliers.\nPlease leave comments, if\n You find anything incorrect. You want to add more information to the topic. You wish to add another example to the topic. You need more details in regards to a specific section. You are unable to execute an example code. "
},
{
	"uri": "/tags/isolationforest/",
	"title": "IsolationForest",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/multivariate/",
	"title": "Multivariate",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/outlier/",
	"title": "Outlier",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/posts/",
	"title": "Posts",
	"tags": ["index"],
	"categories": [],
	"series": [],
	"description": "Post page",
	"content": ""
},
{
	"uri": "/categories/python/",
	"title": "Python",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/python/",
	"title": "Python",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories/statistics/",
	"title": "Statistics",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/univariate/",
	"title": "Univariate",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories/unsupervised-learning/",
	"title": "Unsupervised Learning",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/data-preparation/",
	"title": "Data preparation",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/dimentionality-reduction/",
	"title": "Dimentionality Reduction",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/face-detection/",
	"title": "Face Detection",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/feature-extraction/",
	"title": "Feature Extraction",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/imbalanced-data/",
	"title": "Imbalanced data",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories/machine-learning/",
	"title": "Machine Learning",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories/natural-language-processing/",
	"title": "Natural Language Processing",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/nlp/",
	"title": "NLP",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/nmf/",
	"title": "NMF",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/nmf-clustering/",
	"title": "NMF Clustering",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/non-negative-matrix-factorization/",
	"title": "Non-Negative Matrix Factorization",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/posts/non-negative-matirx-factorization/",
	"title": "Non-Negative Matrix Factorization(NMF) - With Examples in Python",
	"tags": ["Python", "Topic Modeling", "NLP", "NMF", "NMF Clustering", "Recommender Systems", "Face Detection", "Feature Extraction", "Non-Negative Matrix Factorization", "Dimentionality Reduction"],
	"categories": [],
	"series": [],
	"description": "A practical guide about Non-Negative Matrix Factorization(NMF). The article provides examples of how to use NMF for tasks like Topics Modeling, Dimentionality Reduction, Face Detection, Building Recommender Systems, and clustering.",
	"content": "Non-Matrix Factorization, aka NMF, is a widely used algorithm for the analysis of non-negative high dimensional data. The algorithm is handy in extracting meaningful features from a non-negative matrix. It was first introduced in 1994 by Paatero and Tapper. The algorithm has been long used for extracting information from chemical systems using data-driven approaches under the name * self-modeling curve resolution*. It got its name as Non-Negative Matrix Factorization after a popular article from Lee and Seung in 1999. The paper discussed properties of the algorithm and published some simple and useful algorithms for two types of factorizations.[1]\nHow does NMF work? Non-Negative Matrix Factorization is a state of the art technique that is used for extracting important features from a large number of weak and ambiguous attributes. Using these attributes in combination, NMF is able to extract meaningful topics/themes and patterns. For example, NMF is able to produce a context for the word that can occur in different documents.\nblood + bank = Blood Bank\nbank + savings = Financial Institution\nThe algorithm decomposes a matrix V into two lower rank matrices W and H such that when you multiply them, you will get back the original matrix values.\n \\(V \\approx W * H\\)\nPractically, it can be challenging to recover the same matrix, and so, the algorithm tries to get the numbers as close as possible to the original matrix. Let us look at the below example to understand it better.\n Creating a 2D matrix with values 12, 24, 36, and 12.  1 2 3  import numpy as np\rV = np.array([[12, 24],[ 36, 12]])\rprint(V)\r  1 2 3  # Output\r[[12 24]\r[36 12]]\r  Using NMF decomposition to generate W and H Matrices  1 2 3 4  from sklearn.decomposition import NMF\rmodel = NMF(n_components = V.shape[1], init=\u0026#39;random\u0026#39;, random_state=0)\rW = model.fit_transform(X)\rH = model.components_\r  1 2 3 4 5 6 7  # Output - print(W)\r[[0.36187306 3.22309622]\r[6.05892629 0.54819937]]\r# Output - print(H)\r[[5.66230231 1.32023976]\r[3.08739425 7.29802579]]\r    n_components - It is the number of features you want to select as part of the final solution. It is like asking the algorithm to return the most critical n features from the total number of features. If n_components is not set, all features are kept.\n  init - Here, you need to provide the method that will be used to initialize the procedure.\n  random_state - Setting the seed to get reproducible results.\n  Taking the dot product of W and H to get the original V matrix.  1  print(np.dot(W , H))\r  1 2  [[12.00000342 23.99999855]\r[35.99997991 12.0000085 ]]\r  Understanding W and H Matrix When NMF used as a Machine Learning algorithm, W is the weight matrix, and H is the feature Matrix. In the W matrix, each row corresponds to observations, and each column corresponds to a feature. On the other hand, the H matrix contains the feature weights relative to each observation. Here, each row corresponds to a feature, and each column corresponds to a column for each column in the original matrix.\nWhy Non-Negative? The algorithm is named as Non-Negative because it returns non-negative value for the feature and weight matrix. Therefore, all features should either be positive or should have zero values.\nHow Matrix Factorization is Performed  Gradient descent - It is one of the most common techniques which is used for matrix factorization. The technique has many variants such as RMSprop, Adadelta, Adagrad, SGD, and Momentum method.  The Gradient Descent Algorithm 1 2 3 4 5 6 7 8 9 10 11  - Intialize W and H with some random(small) numbers\r- for i until specified_iteration:\r- for row, col in V:\r- if V[row][col] \u0026gt; 0:\r- compute error for elements\r- compute gradient descent for error\r- update the values of W and H\r- Compute total error\r- if error \u0026lt; threshold:\r- break\r- return W, H.Transpose\r  Singular value decomposition(SVD) - SVD is another widely used data reduction technique in Machine Learning. Many international companies like Google, Netflix, and YouTube use this method as a core element in their recommender systems.  Applications of NMF   Dimensionality Reduction Or Feature Extraction - Just like principal component analysis, you can use Non-Negative Matrix Factorization(NMF) for dimensionality reduction or feature extraction.\n  Clustering - NMF is closely related to the unsupervised clustering algorithm and is widely used for document clustering or topic modeling.\n  Recommender Systems - It is a collaborative filtering algorithm based on Non-negative Matrix Factorization and can be used for building a recommender system.\n  Visual Pattern Recognition - In recent years, non-negative matrix factorization (NMF) methods have found attention in the computer vision community. The algorithm has shown promising results with face and gesture recognition.\n  Example #1 - Feature Extraction Using NMF We will be using the digits dataset for this example. Each data point in the digits dataset represents a collection of 8x8 digit images. There are overall 10 classes with ~180 examples per class. There are 1797 images with 64 attributes/features for each one.\n1 2 3 4 5 6 7 8 9 10 11 12 13  from time import time\rimport logging\rimport pylab as pl\rfrom sklearn.decomposition import NMF\rfrom sklearn.datasets import load_digits\rimport matplotlib.pyplot as plt digits = load_digits()\rplt.gray() plt.matshow(digits.images[7]) plt.show()\r  We are preparing data by reshaping the data using n_samples and n_features.\n1 2 3  n_samples = len(digits.images)\rX = digits.images.reshape((n_samples, -1))\rn_features = X.shape[1]\r  From the above dataset, which has 64 features, and we will extract 20 non-negative features using the below code.\n1 2 3 4 5 6  n_components = 20\rprint(f\u0026#34;Building NMF model for extracting {n_components} non-negative features\u0026#34;)\rfeature_model = NMF(n_components=n_components, init=\u0026#39;nndsvd\u0026#39;,\\\rsparseness=\u0026#34;components\u0026#34;,tol=1e-2).fit(X)\rextracted_components = feature_model.components_\r  Using the below code, we will plot the results.\n1 2 3 4 5 6 7 8  n_row, n_col = 4, 4\rimg = pl.figure(figsize=(1.5 * n_col, 1.5 * n_row))\rfor i in range(n_row * n_col):\rpl.subplot(n_row, n_col, i + 1)\rpl.imshow(extracted_components[i].reshape((12, 12)), interpolation=\u0026#39;nearest\u0026#39;)\rpl.xticks(())\rpl.yticks(())\rpl.show()\r  As of now, the results are not very impressive for NMF with 20 components and selected hyperparameters. However, I encourage you to play around with these parameters and see where you get the desired result.\n NMF is a complex algorithm as compared to PCA, because all its components are trained at the same time, and they are also dependent on each other. Thus, if you add another component, the first components which were generated originally may change. Also, we cannot match the variance explained by each component.\n How to choose the number of components in NMF It is challenging to figure how many components are requires as each component cannot be matched to the variance it explains. However, what you can do is fit a new instance of NMF for a number of components, and compare the total variance explained.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  from sklearn.metrics import explained_variance_score\rdef get_optimal_components(components = [1,2,3,4], X_train_nmf = X, X_test_nmf = X):\rvariance_train = []\rvariance_train = []\rfor k in components:\rnmf = NMF(n_components=k).fit(X_train_nmf)\rvariance_train.append(get_score(nmf, X_train_nmf))\rvariance_train.append(get_score(nmf, X_test_nmf))\rreturn(list(zip(components,variance_train)), list(zip(variance_train)))\rdef get_score(model, data, scorer = explained_variance_score):\r\u0026#34;\u0026#34;\u0026#34;Estimate performance of the model on the data \u0026#34;\u0026#34;\u0026#34;\rprediction = model.inverse_transform(model.transform(data))\rreturn scorer(data, prediction)\r  Note: We did not create the test and train dataset. Thus, we will be passing our actual dataset as part of both train and test arguments.\nCalling these functions on our dataset of digits, which we have stored as X will provide the variance explained by the components.\n1 2 3 4  train_var, test_var = get_optimal_components(components = [20, 30, 40, 50],\\\rX_train_nmf = X, \\\rX_test_nmf = X)\rprint(train_var)\r  1 2  # Output\r[(20, 0.6392660812902782), (30, 0.6392660812902782), (40, 0.7276944542659505), (50, 0.7276944542659505)]\r  Looks like with 50 components we can explain approx 73% of the variance.\nExample #2 - Topic Modeling using NMF In natural language processing, topic modeling is used to identify and group similar topics under common themes. Intuitively, documents belonging to a particular topic will have similar words. For this example, we will be using the news summary dataset, which has 4514 summaries.\nWe will be loading the following Python packages, these we will be using to do the necessary cleaning and build NMF topic models.\n1 2 3 4 5 6 7 8 9 10 11 12 13  import re\rimport pandas as pd\rpd.set_option(\u0026#39;display.max_rows\u0026#39;, 500)\rpd.set_option(\u0026#39;display.max_columns\u0026#39;, 500)\rpd.set_option(\u0026#39;display.width\u0026#39;, 1000)\rimport numpy as np\rfrom sklearn.feature_extraction.text import TfidfVectorizer\rfrom nltk.tokenize import word_tokenize\rfrom nltk.corpus import stopwords\rstop = stopwords.words(\u0026#39;english\u0026#39;)\r  Reading the dataset using read_csv function from the pandas package.\n1 2  news_summary = pd.read_csv(\u0026#34;M:/GitHub/data/news-summary/news_summary.csv\u0026#34;, encoding=\u0026#39;latin-1\u0026#39;)\rnews_summary.head()\r  Let's look at the top 5 news article.\n1  news_summary[\u0026#34;ctext\u0026#34;].head()\r  1 2 3 4 5 6  # Output\r0 The Daman and Diu administration on Wednesday ...\r1 From her special numbers to TV?appearances, Bo...\r2 The Indira Gandhi Institute of Medical Science...\r3 Lashkar-e-Taiba\u0026#39;s Kashmir commander Abu Dujana...\r4 Hotels in Mumbai and other Indian cities are t...\r  Next, we will be doing the text cleaning. As part of text cleaning, we do the following tasks.\n Converting text to lower Remove words with character length less than 3 Remove numbers from the text Remove punctuations Remove whitespaces  1 2 3 4 5 6 7 8 9 10  news_summary[\u0026#34;ctext\u0026#34;] = news_summary[\u0026#34;ctext\u0026#34;].apply(lambda x: str(x).lower())\r# Converting all text to lower\r news_summary[\u0026#34;ctext\u0026#34;] = news_summary[\u0026#34;ctext\u0026#34;].apply(lambda x: re.sub(r\u0026#39;\\b\\w{1,3}\\b\u0026#39;, \u0026#39;\u0026#39;, x))\r# removing words with character length less than 3\r news_summary[\u0026#34;ctext\u0026#34;] = news_summary[\u0026#34;ctext\u0026#34;].apply(lambda x:re.sub(r\u0026#39;\\d+\u0026#39;, \u0026#34;\u0026#34;, x))\r# removing numbers\r news_summary[\u0026#34;ctext\u0026#34;] = news_summary[\u0026#34;ctext\u0026#34;].apply(lambda x: re.sub(r\u0026#39;[^\\w\\s]\u0026#39;,\u0026#39;\u0026#39;,x))\r# Removing punctuations\r news_summary[\u0026#34;ctext\u0026#34;] = news_summary[\u0026#34;ctext\u0026#34;].apply(lambda x: re.sub(\u0026#39;\\s+\u0026#39;, \u0026#39;\u0026#39;, x).strip())\r# removing whitespaces\r   Now that we have cleaned the text, we can generate the TF-IDF weighted document-term matrix by using TfidfVectorizer. The idea is to give more weights to the more important terms. After building the tf-idf matrix, we will map each token to their respective tf-idfs.\n1 2 3 4 5 6 7 8 9  vectorizer = TfidfVectorizer(min_df=5, analyzer=\u0026#39;word\u0026#39;, ngram_range=(1, 2))\rvz = vectorizer.fit_transform(list(data[\u0026#39;Snippet\u0026#39;]))\rtf_idf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\rtf_idf = pd.DataFrame(columns=[\u0026#39;tfidf\u0026#39;]).from_dict(dict(tfidf), orient=\u0026#39;index\u0026#39;)\r# Mapping tokens to there tf-idf\r tf_idf.columns = [\u0026#39;tfidf\u0026#39;]\rprint( f\u0026#34;Printing the top 5 words from TF-IDF weighted document-term matrix \\n{tfidf.head()}\u0026#34; )\r  1 2 3 4 5 6 7 8 9 10  Created 4514 X 12753 TF-IDF-normalized document-term matrix\rPrinting the top 5 words from TF-IDF weighted document-term matrix tfidf\raadhaar 5.777574\raadhar 6.930254\raadmi 4.696662\raamir 5.543959\raaps 7.623401\r  Finally, we use NMF to identify and generate 8 topics.\n1 2 3 4 5 6 7  from sklearn.decomposition import NMF\rk = 8\rnmf_8 = NMF(n_components = k, random_state = 10, l1_ratio = .8, init = \u0026#39;nndsvd\u0026#39;, verbose = True, max_iter = 100, tol=0.001)\r# apply the model and extrcating the two smaller matrices\r W = nmf_8.fit_transform(vz)\rH = nmf_8.components_\rprint(f\u0026#34;Actual Number of Iterations: {nmf_8.n_iter_}\u0026#34;)\r  Let's print the topics and also see the top 10 words which mostly describe these topics.\n1 2 3 4 5 6 7  no_top_words = 20\rno_topics_display = 8\rfor topic_idx, topic in enumerate(H[:no_topics_display]):\rprint(\u0026#34;Topic %d:\u0026#34;% (topic_idx))\rprint(\u0026#34;| \u0026#34;.join([terms[i]\rfor i in topic.argsort()[:-no_top_words - 1:-1]]))\r  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  Topic 0:\rfilm | actor | that | khan | with | films | about | kapoor | salman | says\rTopic 1:\rsaid | that | will | have | government | from | with | this | they | their\rTopic 2:\rpolice | woman | were | said | arrested | accused | station | incident | from | allegedly\rTopic 3:\rkohli | cricket | india | test | team | australia | captain | series | virat | england\rTopic 4:\rparty | congress | minister | election | pradesh | uttar | assembly | chief | kejriwal | modi\rTopic 5:\rcourt | supreme | justice | case | high | bench | that | government | apex | order\rTopic 6:\rpakistan | army | kashmir | china | india | indian | chinese | security | pakistani | jammu\rTopic 7:\rnitish | kumar | bihar | lalu | modi | tejashwi | yadav | minister | alliance | prasad\r  We will now draw a bar plot showcasing the word importance for topic number 4.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  def plot_top_term_weights( terms, H, topic_index, top ):\rtop_indices = np.argsort( H[topic_index,:] )[::-1]\rtop_terms = []\rtop_weights = []\rfor term_index in top_indices[0:top]:\rtop_terms.append( terms[term_index] )\rtop_weights.append( H[topic_index,term_index] )\rtop_terms.reverse()\rtop_weights.reverse()\rfig = plt.figure(figsize=(13,8))\rypos = np.arange(top)\rax = plt.barh(ypos, top_weights, align=\u0026#34;center\u0026#34;, color=\u0026#34;orange\u0026#34;,tick_label=top_terms)\rplt.xlabel(\u0026#34;Term Importance - Based on Weights\u0026#34;,fontsize=14)\rplt.tight_layout()\rplt.show()\rplot_top_term_weights(terms, H, 4, 10)\r  Example #3 - Building Recommender Systems using NMF  We can use NMF to generate recommendations for people by reconstructing the matrix using W and H matrix. During the reconstruction of matrix V the algorithm also assigns values to the unknown values which we have filled with zeros in our case. Through the use of latent features, certain weights are assigned to the movies in the column. These values can then be arranged in descending order to determine what all movies should be recommended to the customers.\n We will be using MovieLens for this example. The dataset consists of 100,000 ratings and 3600 tags, which are applied to around 9000 movies by 600+ users.\nFor this example, we will be using sklearn, numpy, and pandas Python module. The downloaded zip file comes with four csv files and one readme text file. Although for this example, we only need the Ratings dataset, we include Movies to get the information on movie names and genres as well.\nIn the below code, we are doing the following:\n Importing the data manipulation packages like numpy and pandas. setting the display setting to fit my requirements. Reading movies and rating dataset Merging the two datasets to get the information in one file.  1 2 3 4 5 6 7 8 9 10 11  import numpy as np\rimport pandas as pd\rpd.set_option(\u0026#39;display.max_rows\u0026#39;, 500)\rpd.set_option(\u0026#39;display.max_columns\u0026#39;, 20)\rpd.set_option(\u0026#39;display.width\u0026#39;, 1000)\rratings = pd.read_csv(\u0026#34;ratings.csv\u0026#34;)\rmovies = pd.read_csv(\u0026#34;movies.csv\u0026#34;)\rmovie_ratings = pd.merge(movies, ratings, on = \u0026#34;movieId\u0026#34;)\rmovie_ratings.to_csv(\u0026#34;movie_ratings.csv\u0026#34;, index = True)\rmovie_ratings.head(5)\r  1 2 3 4 5 6 7 8  # Output\r movieId title genres userId rating timestamp\r0 1 Toy Story (1995) Adventure|Animation|Children|Comedy|Fantasy 1 4.0 964982703\r1 1 Toy Story (1995) Adventure|Animation|Children|Comedy|Fantasy 5 4.0 847434962\r2 1 Toy Story (1995) Adventure|Animation|Children|Comedy|Fantasy 7 4.5 1106635946\r3 1 Toy Story (1995) Adventure|Animation|Children|Comedy|Fantasy 15 2.5 1510577970\r4 1 Toy Story (1995) Adventure|Animation|Children|Comedy|Fantasy 17 4.5 1305696483\r  From the above output, you can see that users with ID 1, 5, 7, 15, and 17 all saw the Toy Story movie. Among these users, the user with ID 15 gave this movie less than average rating, whereas others gave higher ratings.\nThe dataset looks good, but we want one userId per row and one movie per column. We can use pivot function to rearrange the dataset in this particular format.\n1 2  movie_ratings_pivot = movie_ratings.pivot(index = \u0026#39;userId\u0026#39;, columns =\u0026#39;movieId\u0026#39;, values = \u0026#39;rating\u0026#39;)\rmovie_ratings_pivot.head()\r  1 2 3 4 5 6 7 8 9 10  #Output\rmovieId 1 2 3 4 5 6 7 8 9 10 ... 193565 193567\ruserId ... 1 4.0 NaN 4.0 NaN NaN 4.0 NaN NaN NaN NaN ... NaN NaN 2 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN 3 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN 4 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN 5 4.0 NaN NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN [5 rows x 9724 columns]\r  Last, we need to replace NaN value with Zero and convert the data frame into the numpy array.\n1 2  movie_ratings_array = movie_ratings_pivot.fillna(0).as_matrix()\rmovie_ratings_array.head()\r  # Output\rarray([[4. , 0. , 4. , ..., 0. , 0. , 0. ],\r[0. , 0. , 0. , ..., 0. , 0. , 0. ],\r[0. , 0. , 0. , ..., 0. , 0. , 0. ],\r...,\r[2.5, 2. , 2. , ..., 0. , 0. , 0. ],\r[3. , 0. , 0. , ..., 0. , 0. , 0. ],\r[5. , 0. , 0. , ..., 0. , 0. , 0. ]])\rsklearn.decompositon has a function NMF, which can be used to build to fit the final model. We are going to use 200 latent features with both l1 and l2 regularization to generate the W and H matrix.\n1 2 3 4 5 6 7  from sklearn.decomposition import NMF\r# Building model - Basic NMF\r feature_model = NMF(n_components = 200, init=\u0026#39;random\u0026#39;, solver = \u0026#39;mu\u0026#39;,\\\rl1_ratio = 0.5, verbose = True, random_state= 40)\rW = feature_model.fit_transform(movie_ratings_array)\rH = feature_model.components_\r  Now that we have both a W and H matrix. We can use np.dot() function to reconstruct the V matrix. Also, in the dataset, movieId's are not continuous numbers being assigned. So, we need to replace columns names with the actual Id's.\n1 2  reconstructed_V = pd.DataFrame(W.dot(H))\rreconstructed_V.columns = movie_ratings.movieId.unique()\r  Now we will filter out movies which users have already watched, and then we need to select the top 10 recommended movies by sorting the values of the Score column in descending order. Let us see the top 10 recommended movies for the user with id = 1.\n1 2 3 4 5 6 7 8 9 10  i= 0\rtemp_test = reconstructed_V[reconstructed_V.index == i]\rtemp_test = temp_test.T\rtemp_test.reset_index(level=0, inplace=True)\rtemp_test.columns = [\u0026#34;movieId\u0026#34;, \u0026#34;Score\u0026#34;]\rmovieid_already_watched = ratings[ratings.userId == i+1][\u0026#34;movieId\u0026#34;]\rkeep_list = set(temp_test[\u0026#34;movieId\u0026#34;]).difference(set(movieid_already_watched))\rtemp_test = temp_test[temp_test[\u0026#39;movieId\u0026#39;].isin(keep_list)]\rtemp_test_recom = temp_test.sort_values(ascending = False, by = \u0026#34;Score\u0026#34;)\rtemp_test_recom[0:10]\r  1 2 3 4 5 6 7 8 9 10 11 12  # Output\r movieId Score\r1066 1387 0.390069\r2492 3328 0.322647\r1444 1968 0.301258\r784 1027 0.297047\r1745 2342 0.293182\r2274 3019 0.288483\r2799 3745 0.287456\r946 1248 0.286723\r2416 3213 0.280908\r1791 2391 0.274578\r  To get the movie names or tags, you can look into movies or tags dataset. We can also loop through all the userId and save the top 10 recommended movies in a dictionary.\nIt is a good idea to check if the reconstructed matrix had closer results for the movies which were already rated by the user. Below we are comparing the actual and reconstricted ratings for the user with userId (1). If the model is right, then the expectation is to have the numbers in the reconstructed matrix closer to actual ratings.\n1 2 3 4 5 6  Actual_rating = movie_ratings.loc[movie_ratings.userId == 1, [\u0026#34;movieId\u0026#34;,\u0026#34;rating\u0026#34;]].sort_values(by = \u0026#34;rating\u0026#34;, ascending = False).head()\rPredicted_Rating = temp_test.loc[temp_test.movieId.isin(Actual_rating.movieId)].sort_values(by = \u0026#34;movieId\u0026#34;)\rfinal_out = pd.merge(Actual_rating, Predicted_Rating, on = \u0026#34;movieId\u0026#34;)\rfinal_out.columns = [\u0026#34;movieId\u0026#34;,\u0026#34;Actual_Rating\u0026#34;, \u0026#34;Pred_Rating\u0026#34;]\rfinal_out\r  1 2 3 4 5 6 7  # Output\r movieId Actual_Rating Pred_Rating\r0 5060 5.0 5.051744\r1 2872 5.0 4.930985\r2 1291 5.0 5.220716\r3 1298 5.0 4.958132\r4 2948 5.0 5.040785\r  Example #4 - Using NMF For Face Detection For this example, we are using Olivetti faces dataset from AT\u0026amp;T (classification). The dataset is available in sklearn.datasets module.\nFirst, we will load the required Python packages and setting some parameters.\n1 2 3 4 5 6 7 8 9 10 11  from numpy.random import RandomState\rimport matplotlib.pyplot as plt\rimport pylab as pl\rfrom sklearn.datasets import fetch_olivetti_faces\rfrom sklearn.decomposition import NMF, PCA\rn_row, n_col = 2, 3\rn_components = n_row * n_col\rimage_shape = (64, 64)\rrs = RandomState(0)\r  We will now load the dataset and perform centering.\n1 2 3 4 5 6 7 8 9  dataset = fetch_olivetti_faces(shuffle=True, random_state=rs)\rfaces = dataset.data\rn_samples, n_features = faces.shape\r# global centering\r faces_centered = faces - faces.mean(axis=0)\r# local centering\r faces_centered -= faces_centered.mean(axis=1).reshape(n_samples, -1)\r  Let us view one of the sample images.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  def plot_gallery(title, images):\rpl.figure(figsize=(2. * n_col, 2.26 * n_row))\rpl.suptitle(title, size=16)\rfor i, comp in enumerate(images):\rpl.subplot(n_row, n_col, i + 1)\rvmax = max(comp.max(), -comp.min())\rpl.imshow(comp.reshape(image_shape), cmap=pl.cm.gray,\rinterpolation=\u0026#39;nearest\u0026#39;,\rvmin=-vmax, vmax=vmax)\rpl.xticks(())\rpl.yticks(())\rpl.subplots_adjust(0.01, 0.05, 0.99, 0.93, 0.04, 0.)\rplot_gallery(\u0026#34;First centered Olivetti faces\u0026#34;, faces_centered[:n_components])\r  Next, we build the NMF model to estimate the faces and visualize the final results.\n1 2 3  estimator.fit(faces)\rcomponents_ = estimator.components_\rplot_gallery(\u0026#34;First centered Olivetti faces\u0026#34;, components_[:n_components])\r  Example #5 - Building Clusters Using NMF NMF is an efficient method that provides a powerful technique for class discovery. The algorithm has advantages over other methods, such as hierarchical clustering. For building clusters, we will be using bignmf. The following example that illustrates the typical usage of the algorithm is borrowed from HERE.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  from bignmf.models.jnmf.integrative import IntegrativeJnmf\rfrom bignmf.datasets.datasets import Datasets\rDatasets.list_all()\rdata_dict = {}\rdata_dict[\u0026#34;sim1\u0026#34;] = Datasets.read(\u0026#34;SimulatedX1\u0026#34;)\rdata_dict[\u0026#34;sim2\u0026#34;] = Datasets.read(\u0026#34;SimulatedX2\u0026#34;)\rk = 3\riter =100\rtrials = 50\rlamb = 0.1\rmodel = IntegrativeJnmf(data_dict, k, lamb)\rmodel.run(trials, iter, verbose=0)\rprint(model.error)\r# Runs the model\r model.cluster_data()\rprint(model.h_cluster)\r# Clusters the data\r model.calc_consensus_matrices() print(model.consensus_matrix_w)\r#Calculates the consensus matrices\r   Please leave comments, if\n You find anything incorrect. You want to add more information to the topic. You wish to add another example to the topic. You need more details in regards to a specific section. You are unable to execute an example code. "
},
{
	"uri": "/tags/note/",
	"title": "Note",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/notes/",
	"title": "Quick Notes",
	"tags": ["index"],
	"categories": [],
	"series": [],
	"description": "Section dedicated to Python Tips and Quick Notes on Machine Learning.",
	"content": ""
},
{
	"uri": "/tags/recommender-systems/",
	"title": "Recommender Systems",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/smote/",
	"title": "SMOTE",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/notes/smote-dealing-imbalanced-data/",
	"title": "SMOTE for dealing with imbalanced dataset",
	"tags": ["Python", "Note", "SMOTE", "Imbalanced data", "Data preparation", "Upsampling"],
	"categories": [],
	"series": [],
	"description": "A brief note on how SMOTE works and how it can be used to train a model when one class dominates the other.",
	"content": "It is generally not a good idea to train a Machine Learning algorithm when one of the class dominates the other. It is advisable to upsample the minority class or downsample the majority class. Synthetic Minority Over-sampling Technique (SMOTE) is one such algorithm that can be used to upsample the minority class.\nWhen to use SMOTE Machine Learning algorithms find it challenging to learn the patterns if the examples from one of the classes are limited. The final results of a classification problem can also be misleading. For instance, in the case of strokes dataset, only 2% of the total recorded data points consist of individuals who have had a heart attack in the past. In such a case, a Machine Learning algorithm could classify everything as No Stroke and still be correct 98% of the time.\nHow does SMOTE work SMOTE works by manufacturing more minority classes between any two or more real minority instances. Step by step, guide on how the algorithm works.\n Draw a line between the nearest minority instance( as per the parameter, k) Generate new synthetic minority instances on these lines.  Understanding SMOTE parameters The SMOTE() function is available in over_sampling module inside the imbalanced-learn  Python package. Some of the parameters of the SMOTE function are deprecated and will not be available in version 0.60. So I'll only talk about parameters which are very important and are not deprecated. However, to understand them, we need to learn a bit more about how SMOTE works.\n1 2  !pip install imbalanced-learn # using this inside jupyter notebook or spyder GUI\r   The algorithm creates new minority instances at some distance from the existing minority classes, towards there neighbors. So, the question arises, which and how many neighbors are considered for every minority instance.\nThe two important parameters which SMOTE function takes are: sampling_strategy and k_neighbors.\nAt k_neighbors = 1, the closest minority class to a data point from the same class is considered. At k_neighbors = 2, both first and second closest neighbor of the same class is considered. The new data points are synthesized on the imaginary straight line, which connects the points. The exercise is repeated for all the minority data points.\nSmote at k_neighbors = 1 Smote at k_neighbors = 2 sampling_strategy helps define how to resample the data set. The parameter can take inputs in the following forms:\n  float - it corresponds to the desired ratio between the number of samples from minority class over the majority class. However, this option is only available for the binary classification problem. An error is raised when passed for multi-class classification.\n  str - specify the class to be resampled. The possible choices are:\n    \u0026lsquo;minority\u0026rsquo;: only the minority class is resampled\n  \u0026lsquo;not minority\u0026rsquo;: All classes but the minority class is resampled\n  \u0026lsquo;not majority\u0026rsquo;: All classes but the majority class is resampled\n  \u0026lsquo;all\u0026rsquo;: resample all classes\n  \u0026lsquo;auto\u0026rsquo;: equivalent to \u0026lsquo;not majority\u0026rsquo;\n  dict - In a dictionary, key corresponds to the target variable classes. The values correspond to the number of samples to be created for each target class.  Example #1 SMOTE function code in Python We will load a stroke dataset and check the distribution of target variable classes.\n1 2 3 4  import pandas as pd\rfrom imblearn.over_sampling import SMOTE\rstrokes = pd.read_csv(\u0026#34;M:/GitHub/data/healthcare-dataset-stroke-data/train_2v.csv\u0026#34;)\rround(strokes.stroke.value_counts()/strokes.shape[0] * 100, 2)\r  1 2 3  # Output\r0 98.2\r1 1.8\r  You can see the dataset is highly imbalanced, with only ~2% of observations comprising of people who have had a heart attack.\nLet us fit SMOTE and check out the number of observations in each category of the target variable.\n1 2 3 4 5 6 7 8 9  Y_train = strokes[\u0026#34;stroke\u0026#34;]\rX_train = strokes.drop([\u0026#39;stroke\u0026#39;, \u0026#34;id\u0026#34;], axis = 1)\rX_train = pd.concat([pd.get_dummies(X_train[col]) for col in X_train], axis=1, keys=X_train.columns)\r# Prepared dataset, created dummy variable\r sm = SMOTE(random_state=2)\rX_train, Y_train = sm.fit_sample(X_train, Y_train)\r# Fit the SMOTE\r np.bincount(Y_train)\r# Getting the count of target variable class\r   Example #2 SMOTE function code in Python In last example we saw that both the target levels had the same count. Sometimes you may be interested in increaing the minority class to a certain pre-defined numbers. For example, let's say you want to maintain 90 - 10 raito between 0 and 1.\n1 2 3 4 5 6 7 8 9  Y_train = strokes[\u0026#34;stroke\u0026#34;]\rX_train = strokes.drop([\u0026#39;stroke\u0026#39;, \u0026#34;id\u0026#34;], axis = 1)\rX_train = pd.concat([pd.get_dummies(X_train[col]) for col in X_train], axis=1, keys=X_train.columns)\r# Prepared dataset, created dummy variable\r sm = SMOTE(random_state = 2, sampling_strategy = {0: 42617, 1: 4261} )\rX_train, Y_train = sm.fit_sample(X_train, Y_train)\r# Fit the SMOTE using dict as sampling strategy\r np.bincount(Y_train)/Y_train.shape[0] * 100\r# Getting the count of target variable class\r   1 2  # Output\rarray([90.9104484, 9.0895516])\r  Please leave comments, if\n You find anything incorrect. You want to add more information to the topic. You wish to add another example to the topic. You need more details in regards to a specific section. You are unable to execute an example code.  "
},
{
	"uri": "/tags/topic-modeling/",
	"title": "Topic Modeling",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/upsampling/",
	"title": "Upsampling",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/global-variable/",
	"title": "Global variable",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/local-variable/",
	"title": "Local Variable",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/notes/variable-scoping/",
	"title": "Scope of Variables",
	"tags": ["Python", "Note", "Global variable", "Local Variable"],
	"categories": [],
	"series": [],
	"description": "A quick note with examples on scope of variables in Python.",
	"content": "Scope in computer programming language means the visibility of variables. It is the scope that defines which part of the program can use/see the variable. In general, a variable, once defined, can be accessed from any part of the code. However, sometimes, we would like to restrict the use of the variable to a specific section of the code. Programmers may want to do this to avoid unexpected errors.\nFor example, you may like to limit the scope of a variable to a specific function. This way, any changes introduced to the function will not impact the whole code in case something goes wrong.\nVariables are divided into two groups considering the above restriction criteria.\n Global Variables Local Variabls  Global Variables In Python, a global variable is defined outside the function. The variable can then be accessed outside or inside the function.\n1 2 3 4 5 6  var = 20\rdef demo():\rprint(var)\rdemo()\r# Ouptut :- 20\r   If you try to modify a global variable inside a function, Python will throw an error stating UnboundLocalError which indicates that the local variable was referenced before assignment.\n1 2 3 4 5 6 7  var = 20\rdef demo():\rvar *= 20\rprint(var)\rdemo()\r# Output :- UnboundLocalError: local variable \u0026#39;var\u0026#39; referenced before assignment\r   To modify the values, we need to declare the variable as using the global keyword.\n1 2 3 4 5 6 7 8  var = 20\rdef demo():\rglobal var\rvar *= 20\rprint(var)\rdemo()\r# Ouptut :- 400\r   Local Variables A variable that can only be accessed inside a function is called as a local variable. In other words, variables that are changed or created inside of a function are considered local variables. When you try to access local variables from outside, they return the NameError: name 'zz' is not defined.\n1 2 3 4 5 6  def demo():\rzz = 20\rprint(zz)\rprint(zz)\r# Ouptut :- NameError: name \u0026#39;zz\u0026#39; is not defined\r   Please leave comments, if\n You find anything incorrect. You want to add more information to the topic. You wish to add another example to the topic. You need more details in regards to a specific section. You are unable to execute an example code.  "
},
{
	"uri": "/posts/seaborn-tutorial/",
	"title": "A Step By Step Seaborn Tutorial",
	"tags": ["Python", "Tutorial", "Seaborn", "Exploratory data analysis", "Plot", "Graph"],
	"categories": [],
	"series": [],
	"description": "A complete guide on how to use Seaborn library for data visualization in python. A tool that makes exploratory data analysis easy and efficient.",
	"content": "Introduction To Seaborn Seaborn is a python library which is built on top of matplotlib package. The package is also closely integrated with pandas data structure. Seaborn functions aim to make exploring and data understanding easy through visualization. The functions provided in seaborn can work on data frames and arrays. While building graphs the functions can internally perform statistical aggregations and generate informative graphs. In this article, we will leanr how to draw different types of charts using seaborn library in Python.\nHow to install seaborn library To install seaborn package use pip or conda in Jupyter Notebook as given below:\n1 2 3 4 5 6  pip install seaborn\r# install using anaconda command line\r conda install seaborn\r# install using anaconda command line\r !pip install seaborn\r# install from jupyter notebook/spyder    Once installed use import the library using import function. If you want you can also give alias for easy calling of the functions from the module.\n1  import seaborn as sns\r  How to choose color palettes in Seaborn For any sortof visualization colors play an important role. Colors can help highlight data patterns if used effectively. Seanborn provides wide range of color palettes. It also makes it easy to select and use these palettes. Now let's take a quick look into how we can change the color style. We can set the style using set() method.\n1 2 3  import seaborn as sns\rimport matplotlib.pyplot as plt\rsns.set()\r  You can use color_palette() function to generate colors in seaborn. Many functions in seaborn internally give provision to mention color palettes through palette argument. The package also provides pre-defined names of color palettes or colormaps. Let's check out the default color palette. The seaborn provides six variations of the default color theme.\nThe choice of color theme/scheme is dependent on the nature of your data. You can learn more on types of color schemes from the color brewer website.\nSeaborn Default color palette We can use the follow code to check the default color palette.\n1  sns.palplot(sns.color_palette())\r  You can also change the number of colors you need through the use of n_colors argument. To change the default color theme use palette argumnet as given below.\n1  sns.palplot(sns.color_palette(palette = \u0026#34;pastel\u0026#34;, n_colors = 4))\r  Seaborn Choosing colors for arbitrary number of categories You can use hls or hls_palette() color space when you want to visualize categorical variables without emphazising on a specific category.\n1 2  sns.palplot(sns.color_palette(\u0026#34;hls\u0026#34;, 5))\rsns.palplot(sns.hls_palette(5))\r  Seaborn choosing colors from color brew palette You can use color brew tool for getting visually pleasing color palettes. Below I ma providing some of th most popular color palettes.\n1 2  sns.palplot(sns.color_palette(\u0026#34;Set2\u0026#34;))\rsns.palplot(sns.color_palette(\u0026#34;Paired\u0026#34;))\r  Seaborn choosing sequential color palette This type of color scheme is used for sequential data. A sequential data has a range where low value are relatively uniteresting compared to high values or vis a versa. Seaborn provides a great number of options for these palettes. They are mostly named after the dominant color.\n1 2  sns.palplot(sns.color_palette(\u0026#34;Blues\u0026#34;))\rsns.palplot(sns.light_palette(\u0026#34;purple\u0026#34;, reverse=True))\r  Choosing custom color palette color_palette() function makes it very easy to set your own colors as part of chart style.\n1 2  custom = [\u0026#34;#E5C494\u0026#34;, \u0026#34;#FFFFFF\u0026#34;, \u0026#34;#318EFE\u0026#34;, \u0026#34;#e74c3c\u0026#34;, \u0026#34;#34495e\u0026#34;]\rsns.palplot(sns.color_palette(custom))\r  How to change the color palette in seaborn Color schemes can be changed in seaborn using set_palette() function. Use the blow code to set your style.\n1 2  import seaborn as sns\rsns.set_palette(\u0026#34;purple\u0026#34;)\r  How to change seaborn themes The seaborn package provides five themes to work with: darkgrid, whitegrid, dark, white, and ticks. The choice of theme is a personal preference. By default, the seaborn works with darkgrid theme.\nYou can set a new theme by using set_style() functions as mentioned in the code below. Once set all the following charts will be as per the new theme\n1 2 3  import seaborn as sns\rsns.set_style(\u0026#34;whitegrid\u0026#34;)\rtips = sns.load_datasets(\u0026#34;tips\u0026#34;)\r  Seaborn - histogram Python You can use distplot() from seaborn to plot a histogram. By default, the function also fits a kernel density estimate also represented by KDE. In the code below we will see how to draw the historam with pestal color pestal.\n1 2 3 4 5 6 7 8 9 10 11  import numpy as np\rimport pandas as pd\rimport seaborn as sns\rimport matplotlib.pyplot as plt\rfrom scipy import stats\rseaborn.set_color_codes(palette=\u0026#39;Dark2_r\u0026#39;)\r# Setting a new color palette style\r randnum = np.random.normal(size=1000)\rsns.distplot(randnum)\r  How to change the bins in histogram 1  sns.distplot(randnum, bins=30, kde=False)\r  How to plot only the distribution 1  sns.distplot(randnum, bins=30, hist=False)\r  Seaborn - scatter plot Python Scatter plots are the mainstay of statistical analysis. They help us understandthe relationship between two continuous variables. To draw a scatter plot in seaborn you can use either relplot() or scatterplot() functions. The replot() function can also be used to draw a lineplot() and can also provide other functionalities like generating facets and all.\nTo draw a simple scatter plot use the below code.\n1 2 3 4 5  tips = sns.load_dataset(\u0026#34;tips\u0026#34;)\rsns.relplot(x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, data=tips)\rsns.scatterplot(x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, data=tips)\r# Same plot using scatterplot()\r   How to draw scatter plot by group variable While two dimensions can provide a good insight into the data, adding another dimension could help us dig deeper into the data patterns and can reveal really good insights. Question is how can be add the third dimension? Well a third dimension can be added in multiple ways:\n Using colors using marker style Using different sizes  How to draw scatter plot by group using color To represent the thrid variable(categorical) we can use hue argument. Let us see, between smokers and non-smoker who gave more tips in relationship to the total_bill.\n1 2  sns.relplot(x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, hue=\u0026#34;smoker\u0026#34;, data=tips)\rsns.scatterplot(x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, hue=\u0026#34;smoker\u0026#34;, data=tips)\r  How to create scatter plot by group variable using marker To add the marker you can use style argument.\n1 2 3  sns.set_palette(\u0026#34;Dark2\u0026#34;)\rsns.relplot(x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, hue=\u0026#34;smoker\u0026#34;, style=\u0026#34;smoker\u0026#34;, data=tips)\rsns.scatterplot(x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, hue=\u0026#34;time\u0026#34;, style=\u0026#34;time\u0026#34;, data=tips)\r   In the above examples, the third variable added is categorical. But if a numerical variables is passed inhue argumnet then the plot either selects sequential colors or uses size to distinguish the data points on the scatter plot.\n How to create scatter plot by group variable using size 1 2  sns.relplot(x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, hue=\u0026#34;size\u0026#34;, data=tips)\rsns.scatterplot(x=\u0026#34;total_bill\u0026#34;, y=\u0026#34;tip\u0026#34;, hue=\u0026#34;size\u0026#34;, data=tips)\r  Seaborn - line chart Pyhton Mostly, we draw line charts when we are interested in knowing how the values of a specific variable changes over time. To draw line plot you can use relplot() functions with argumnet kind = line() or you can use lineplot() functions. In the coming examples we will be using the functions interchangibaly.\nExample #1 Seaborn default line Chart For example, we will be draw a trend chart showing the suicides/100k pop trend from 1985 till 2016.\n1 2  suicide = pd.read_csv(\u0026#34;master.csv\u0026#34;)\rsns.relplot(x=\u0026#34;year\u0026#34;, y=\u0026#34;suicides_no\u0026#34;, sort=False, kind=\u0026#34;line\u0026#34;, data=suicide);\r  Example #2 Seaborn only line Chart no CI By default, the relplot() for kind = \u0026quot;line\u0026quot; provides the confidence interval. The light blue region in the above chart represents the confidence intervals. If you do not want these then you need to pass ci = None as an argumnet.\n1  sns.lineplot(x=\u0026#34;year\u0026#34;, y=\u0026#34;suicides/100k pop\u0026#34;, sort=True, ci = None, data=suicide)\r  Example #3 Seaborn mutiple lines plot Just like scatterplot() the lineplot() is also flexible and can show upto three aditional variables using hue, style, and size elements. Let's check how the suicides/100k pop have changed per year for different genders.\n1  sns.lineplot(x=\u0026#34;year\u0026#34;, y=\u0026#34;suicides/100k pop\u0026#34;, sort=True, hue = \u0026#34;sex\u0026#34;, data=suicide)\r  It is evident from the above that suicides per 100k population is way much higher than the female. Although, both genders saw declining trend till 2013. However, 2015 saw a steep growth in suicide for males.\nExample #3 Seaborn Multiple line Chart Let's look at one more example by plotting the above parameter by age groups.\n1 2  sns.relplot(x=\u0026#34;year\u0026#34;, y=\u0026#34;suicides/100k pop\u0026#34;, sort=True, hue = \u0026#34;age\u0026#34;,\\\rci = None, kind = \u0026#34;line\u0026#34; , data=suicide)\r  So far we learned to visualize relationships between continuous varibales using histograms, scatter plots adn line plots. We learned how to use hue, size and style to understand these variables by the group variables.\nSeaborn plotting categorical variables  Seaborn provides multiple different ways in which we can visualize relationships between categorical variables. You can draw categorical plots using catplot() function aling with kind argument or by using the below mentioned functions.\n The different kinds of categorical plots are:\n Distribution plots for categorical variables   boxplot() boxenplot()  Point Estimate plots for categorical variables   barplot() countplot() pointplot()  Scatter plots for categorical variables   stripplot() swarmplot()  We will discuss and learn how to draw all the above mentioned plots in seaborn. For all the seaborn examples we will be using suicide dataset.\nSeaborn - boxplot Python A boxplot visualization helps us to understand the distribution of quantitative variable across different levels of a categorical variable. The boxplots are also widely used to identify outliers using a method which is based on inter-quartile range.\nExample #1 - Verticle boxplot seaborn Let's see what is the distribution of gdp_per_capita ($) variable looks like for different sex groups using the boxplot.\n1 2  sns.boxplot(x=\u0026#34;sex\u0026#34;, y=\u0026#34;gdp_per_capita ($)\u0026#34;, data=suicide)\rsns.catplot(x=\u0026#34;sex\u0026#34;, y=\u0026#34;gdp_per_capita ($)\u0026#34;, kind = \u0026#34;box\u0026#34;, data=suicide)\r  Example #2 - Horizontal boxplot seaborn In order to draw the horizontal boxplot we need to change the orientation of the axes usin orient=\u0026quot;h\u0026quot; argument. Plus, you should swap the x and y arguments. So that y represents the categorical variable and x represents the continuous variable.\n1 2  sns.boxplot(y=\u0026#34;sex\u0026#34;, x=\u0026#34;gdp_per_capita ($)\u0026#34;, orient=\u0026#34;h\u0026#34;,data=suicide)\rsns.catplot(y=\u0026#34;sex\u0026#34;, x=\u0026#34;gdp_per_capita ($)\u0026#34;, kind = \u0026#34;box\u0026#34;, orient = \u0026#34;h\u0026#34;, data=suicide)\r  Example #3 - Boxplot with 2nd categorical variable seaborn If you wish to deep dive and learn how the ditribution of numerical variable changes by a group variable you can use hue argument, just like scatter plot.\n1 2 3  tips = sns.load_dataset(\u0026#34;tips\u0026#34;)\rsns.boxplot(x=\u0026#34;size\u0026#34;, y=\u0026#34;total_bill\u0026#34;, hue=\u0026#34;day\u0026#34;, data=tips)\rsns.catplot(x=\u0026#34;size\u0026#34;, y=\u0026#34;total_bill\u0026#34;, hue = \u0026#34;day\u0026#34; , kind = \u0026#34;box\u0026#34;, data=tips)\r  Example #4 - Bonus - Genrating grids The catplot() function allows you to conclude your visualization using facets. To generate grids or facets pass the categorical variable name in col argument. In case the number of levels for the categorical variable which is passed in col argument is high you can use col_wrap argument as shown below.\n1 2 3  sns.catplot(x=\u0026#34;cut\u0026#34;, y=\u0026#34;price\u0026#34;, col = \u0026#34;clarity\u0026#34;,\rcol_wrap = 4, data = diam, kind=\u0026#34;box\u0026#34;,\rheight=4, aspect=.7)\r  Seaborn - boxenplot Python A boxenplot is very similar to a boxplot as it used to visualize distribution using quantiles. But compared to boxplot the boxenplot gives more infomration about the shape of distribution especially at the tails.\nLet's see how some of the above drawn box plots will look when populated as boxenplot.\nExample #1 - Verticle boxenplot seaborn 1 2  sns.boxenplot(x=\u0026#34;sex\u0026#34;, y=\u0026#34;gdp_per_capita ($)\u0026#34;, data=suicide)\rsns.catplot(x=\u0026#34;sex\u0026#34;, y=\u0026#34;gdp_per_capita ($)\u0026#34;, kind = \u0026#34;boxen\u0026#34;, data=suicide)\r  Example #2 - Horizontal boxenplot seaborn 1 2 3 4  sns.boxenplot(y=\u0026#34;sex\u0026#34;, x=\u0026#34;gdp_per_capita ($)\u0026#34;, orient=\u0026#34;h\u0026#34;,data=suicide)\rsns.catplot(y=\u0026#34;sex\u0026#34;, x=\u0026#34;gdp_per_capita ($)\u0026#34;, kind = \u0026#34;boxen\u0026#34;, orient = \u0026#34;h\u0026#34;, data=suicide)\r  Example #3 - Boxenplot with 2nd categorical variable seaborn 1 2 3 4 5  tips = sns.load_dataset(\u0026#34;tips\u0026#34;)\rsns.boxenplot(x=\u0026#34;size\u0026#34;, y=\u0026#34;total_bill\u0026#34;, hue=\u0026#34;day\u0026#34;, data=tips)\rsns.catplot(x=\u0026#34;size\u0026#34;, y=\u0026#34;total_bill\u0026#34;, hue = \u0026#34;day\u0026#34; , kind = \u0026#34;boxen\u0026#34;, data=tips)\r  Seaborn - countplot Python The count plot is also a dribution plot which is similar to hitorgrams. The only difference being that count plots are generated for categorical variable as compared to histograms which help visualize dritribution of quantitative variables.\nExample #1 Verticle count plot For this example, lets see the distribution of categorical age variable from the suicide dataset.\n1 2  sns.countplot(x=\u0026#34;age\u0026#34;, data=suicide)\rsns.catplot(x=\u0026#34;age\u0026#34;, kind = \u0026#34;count\u0026#34;, data=suicide)\r  The above chart sugests we have equal number of observations in all six age categories.\nExample #2 Horizontal count plot To draw a horizontal count plot you can mention the variable name in argment y instead of x. Let's check the distribution of generation variabe.\n1 2  sns.countplot(y=\u0026#34;generation\u0026#34;, data=suicide)\rsns.catplot(y=\u0026#34;generation\u0026#34;, kind = \u0026#34;count\u0026#34;, data=suicide)\r  Example #3 countplot by a categorical variables We can use hue to look at the distribution of categorical variable by the grouped variable. Let's dig deeper into generation to check out how the distribution by male and female groups.\n1 2  sns.countplot(x=\u0026#34;generation\u0026#34;, hue =\u0026#34;sex\u0026#34;, data=suicide)\rsns.catplot(y=\u0026#34;generation\u0026#34;, hue = \u0026#34;sex\u0026#34;, kind = \u0026#34;count\u0026#34;, data=suicide)\r  Seaborn - barplot Python In seaborn barplots are used to plot the central tendency estimates for the numerical variables along with the error bars.\nExample #1 Vertical barplot Let's check out the central tendency estimates of gdp_per_capita ($) by the generation in suicide dataset.\n1 2  sns.barplot(x=\u0026#34;generation\u0026#34;, y =\u0026#34;gdp_per_capita ($)\u0026#34;, data=suicide)\rsns.catplot(y=\u0026#34;generation\u0026#34;, hue = \u0026#34;sex\u0026#34;,kind = \u0026#34;bar\u0026#34;, data=suicide)\r  Example #2 barplot changing colors To change the color of bars you can use color, palette, or facecolor like arguments.\n:Using colors:\n1 2  sns.barplot(x=\u0026#34;generation\u0026#34;, y =\u0026#34;gdp_per_capita ($)\u0026#34;,\rcolor = \u0026#34;green\u0026#34;, data =suicide)\r  :Using palette:\n1 2  sns.barplot(x=\u0026#34;generation\u0026#34;, y =\u0026#34;gdp_per_capita ($)\u0026#34;,\rpalette = \u0026#34;Blues_d\u0026#34;, data =suicide)\r  :Using facecolor:\n1 2 3  sns.barplot(x=\u0026#34;generation\u0026#34;, y =\u0026#34;gdp_per_capita ($)\u0026#34;,\rlinewidth=4,facecolor = (1, 1, 1, 0), errcolor=\u0026#34;.5\u0026#34;, edgecolor = \u0026#34;.5\u0026#34;, data =suicide)\r  Example #3 barplot - Three dimensions 1 2  sns.barplot(x=\u0026#34;generation\u0026#34;, y =\u0026#34;gdp_per_capita ($)\u0026#34;,\rhue = \u0026#34;sex\u0026#34;, data =suicide)\r  Seaborn - pointplot Python Point plots are similar to bar plots as they also show the central tendency estimate along with the error bars. However, you may find points to be more useful for comparing levels of one or more than one categorical variable.\nExamplt #1 point plot Python 1  sns.pointplot(x=\u0026#34;generation\u0026#34;, y =\u0026#34;gdp_per_capita ($)\u0026#34;, data =suicide)\r  Examplt #2 point plot by group variable Python 1 2 3 4 5 6 7  tips = sns.load_dataset(\u0026#34;tips\u0026#34;)\rsns.pointplot(x=\u0026#34;size\u0026#34;, y =\u0026#34;total_bill\u0026#34;, hue = \u0026#34;day\u0026#34;,data =tips, dodge = True)\rsns.catplot(x=\u0026#34;size\u0026#34;, y =\u0026#34;total_bill\u0026#34;, hue = \u0026#34;day\u0026#34;, data =tips, dodge = True, kind = \u0026#34;point\u0026#34;)\r  Seaborn - stripplot Python The stripplots can be used as substitutes for boxplots especially when you want to showcase all the observations as data points.\nExample #1 Stripplot in Python 1 2 3 4  import seaborn as sns\rsns.set(style=\u0026#34;darkgrid\u0026#34;)\rtitanic = sns.load_dataset(\u0026#34;titanic\u0026#34;)\rsns.stripplot(y=titanic.fare)\r  Example #2 Stripplot group by categorical variable 1 2 3  sns.stripplot(x = \u0026#34;class\u0026#34;,y = \u0026#34;fare\u0026#34;, data = titanic)\rsns.catplot(x = \u0026#34;class\u0026#34;,y = \u0026#34;fare\u0026#34;, data = titanic, kind = \u0026#34;strip\u0026#34;)\r  Example #3 Stripplot with jitters Jitters can be really helpful in visualizing the distribution. To help you understand the importance we will be drawing two charts one with jitter = False as argument and one with jitter = True.\nBelow is the plot with jitter = False\n1 2  sns.stripplot(x = \u0026#34;class\u0026#34;,y = \u0026#34;age\u0026#34;, data = titanic, jitter = False)\r  Below is the plot with jitter = True\n1 2  sns.catplot(x = \u0026#34;class\u0026#34;,y = \u0026#34;age\u0026#34;, data = titanic, kind = \u0026#34;strip\u0026#34;, jitter = True)\r  Example #4 Stripplot with two categorical variables 1 2 3 4  sns.stripplot(x = \u0026#34;class\u0026#34;,y = \u0026#34;age\u0026#34;, hue = \u0026#34;alive\u0026#34;,\rdata = titanic, jitter = True)\rsns.catplot(x = \u0026#34;class\u0026#34;,y = \u0026#34;age\u0026#34;, hue = \u0026#34;alive\u0026#34;,\rdata = titanic, kind = \u0026#34;strip\u0026#34;, jitter = True)\r  You can see that compared to third class more number of individuals servived in first class.\nExample #5 Stripplot with differnt asthetics In this example, we will see how change the following arguments\n shape of the markers: marker =  use new palettes: palette = size of the markers: size = opacity of markers: alpha = markeredge colors: edgecolor =  1 2 3 4  sns.stripplot(x = \u0026#34;class\u0026#34;,y = \u0026#34;age\u0026#34;, hue = \u0026#34;alive\u0026#34;, palette=\u0026#34;Set2\u0026#34;, size=5, marker=\u0026#34;D\u0026#34;,\redgecolor=\u0026#34;red\u0026#34;, alpha=.50, data = titanic, jitter = True)\r  Seaborn - swarmplot Python The plot is exactly same as striplot with only difference that unlike strip plot the points are adjusted such that they dont overlap. To built the plot you can use either catplot() function with kind = swarm argumnet or else you can use swarmplot() function.\nExample #1 swarmplot group by categorical variable 1 2 3  sns.swarmplot(x = \u0026#34;class\u0026#34;,y = \u0026#34;fare\u0026#34;, data = titanic)\rsns.catplot(x = \u0026#34;class\u0026#34;,y = \u0026#34;fare\u0026#34;, data = titanic, kind = \u0026#34;swarm\u0026#34;)\r  Example #2 swarmplot with two categorical variable 1 2 3 4  sns.swarmplot(x = \u0026#34;class\u0026#34;,y = \u0026#34;age\u0026#34;, hue = \u0026#34;alive\u0026#34;,\rdata = titanic)\rsns.catplot(x = \u0026#34;class\u0026#34;,y = \u0026#34;age\u0026#34;, hue = \u0026#34;alive\u0026#34;,\rdata = titanic, kind = \u0026#34;swarm\u0026#34;)\r  Seaborn - FacetGrid plot Python One of the most popuar ways to plot multiple plots by ensuring charts are still readable is through the use of grids. In seabborn library, we have FacetGrid() function that provides this functionality. It can be used to draw upto three dimensions using row, col and hue.\nLet's see how we can plot fairs by class using titanic data. To generate grids we would be required to first create the facets.\n1 2  titanic = sns.load_dataset(\u0026#34;titanic\u0026#34;)\rplot = sns.FacetGrid(data = titanic, col = \u0026#34;class\u0026#34;)\r  Now, that we have grids created we can map any chart using the map method. Let's add a scatter plot between age and fare per class.\n1 2 3  titanic = sns.load_dataset(\u0026#34;titanic\u0026#34;)\rplot = sns.FacetGrid(data = titanic, col = \u0026#34;class\u0026#34;)\rplot.map(sns.scatterplot, \u0026#34;age\u0026#34;, \u0026#34;fare\u0026#34;)\r  Let's see how we could add the two categorical variables using hue.\n1 2 3  titanic = sns.load_dataset(\u0026#34;titanic\u0026#34;)\rplot = sns.FacetGrid(data = titanic, col = \u0026#34;class\u0026#34;, hue = \u0026#34;sex\u0026#34;)\rplot.map(sns.scatterplot, \u0026#34;age\u0026#34;, \u0026#34;fare\u0026#34;)\r  As we have too different coolor points on each plot. It is a good practice to add the legend for the ease of redability. To add legend we can use low level function called as add_legend()\n1 2 3 4  titanic = sns.load_dataset(\u0026#34;titanic\u0026#34;)\rplot = sns.FacetGrid(data = titanic, col = \u0026#34;class\u0026#34;, hue = \u0026#34;sex\u0026#34;)\rplot.map(sns.scatterplot, \u0026#34;age\u0026#34;, \u0026#34;fare\u0026#34;)\rplot.add_legend()\r  Seaborn - pairwise plot Python Pairwise plot is a very interesting plot. It represents a lot of information by plotting small subplots in a gird like arrangement. In each gird row and column is assigned to a different variable creating a pairwise bivariate relationship plot at the intersection. The diagonal plots represent univariate information, mostly related to ditribution.\nThe seaborn package in Python provides two functions IE PairGrid() and pairplot() using which you can plot the pairwise relationships. Let's look at the two functions one by one.\nFor examples on pairwise relationship plots we will be using car crashes dataset from seaborn package\nSeaborn - PairGrid Function Pairwise plot The PairGrid() function is very similar to FacetGrid(). Just like FacetGrid you need to first initialize the grid and then useing map method generate the plots.\n1 2  crashes = sns.load_dataset(\u0026#39;car_crashes\u0026#39;)\rcrashes.head()\r  1 2  plot = sns.PairGrid(crashes)\rplot.map(plt.scatter)\r  The pariwise matrix shown above can be divided into following parts and subparts:\n Diagonal charts Off diagonal charts  upper triangle charts lower triangle charts     You can refer to these parts and change the chart type as per your requirment.\n Example #1 Changing diagonal charts Updating diagnoal charts to histogram from scatter plot.\n1 2 3  plot = sns.PairGrid(crashes.iloc[:, 3:8])\rplot.map_diag(plt.hist)\rplot.map_offdiag(plt.scatter)\r  Example #2 Changing off-diagonal charts Changing upper triangle charts to kdeplot while keeping the diagonal charts as histograms.\n1 2 3 4  plot = sns.PairGrid(crashes.iloc[:, 3:7])\rplot.map_diag(plt.hist)\rplot.map_uper(sns.kdeplot)\rplot.map_lower(plt.scatter)\r  Example #3 Adding Categorical variable In this example, we will be using mpg dataset. Lets\u0026rsquo; see how the pairwise plot looks like by the cylinder variable. And now, because we are trying to understand the distribution or relationship between levels of a categorical variable we will be adding a legend as well.\n1 2 3 4  plot = sns.PairGrid(mpg, vars = [\u0026#39;displacement\u0026#39;, \u0026#39;horsepower\u0026#39;, \u0026#39;weight\u0026#39;], hue = \u0026#34;cylinders\u0026#34;)\rplot.map_diag(plt.hist)\rplot.map_offdiag(plt.scatter)\rplot.add_legend()\r  Seaborn - pairplot function The other function which you can use to create a pariwise plot is pairplot(). The function is less flexible but faster in comparison to PairGrid(). Let's quickly see how we can recreate the some of the above plot. You can use pairplot() for quick analysis but for deeper and more customizations PairGrid() function is a much better choice.\nPlotting a pairwise plot with cylinder as categorical variable.\n1  sns.pairplot(mpg, vars = [\u0026#39;displacement\u0026#39;, \u0026#39;horsepower\u0026#39;, \u0026#39;weight\u0026#39;], hue=\u0026#34;cylinders\u0026#34;)\r  Changing diagonal plots to histograms.\n1  sns.pairplot(mpg, vars = [\u0026#39;displacement\u0026#39;, \u0026#39;horsepower\u0026#39;, \u0026#39;weight\u0026#39;], hue=\u0026#34;cylinders\u0026#34;)\r  Please leave comments, if\n You find anything incorrect. You want to add more information to the topic. You wish to add another example to the topic. You need more details in regards to a specific section. You are unable to execute an example code.  "
},
{
	"uri": "/tags/exploratory-data-analysis/",
	"title": "Exploratory data analysis",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/graph/",
	"title": "Graph",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/plot/",
	"title": "Plot",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories/programming/",
	"title": "Programming",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/python-beginners-tutorial/",
	"title": "Python Beginners Tutorial",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/posts/python-programming-tutorial/",
	"title": "Python Programming Tutorial",
	"tags": ["Python", "Tutorial", "Python Beginners Tutorial"],
	"categories": [],
	"series": [],
	"description": "A brief introduction to Python programming for beginners with examples.",
	"content": "Python is a powerful and versatile programming language. It is easy to understand and learn. Today, the python programming language is widely used in the industry. Some of the applications of python programming include Web Development, Robotics, 3D CAD Applications, Data Analysis, Face Detection, Machine Learning, and Artificial Intelligence. In this tutorial, we will cover all the fundamental building blocks of Python!\nHistory of Python The programming language Python was developed by Guido van Rossum in the late 1980's. However, the implementation of the language started to take place in 1989. The version 1 of the language was released in January 1994. The primary functional tools included were lambda, map, reduce, and filter. In October 2000, version 2.0 of the programming language was released, and a year later Python Software Foundation(PSF), a nonprofit organization, was also formed. The organization is devoted to advancing open source technology related to the Python programming language.\nIn December 2008, Python 3.0, also sometimes called Py3K or Python 3000, was released to rectify fundamental design flaws of the earlier versions. As full backward compatibility was not possible, a parallel world of Python 3 and Python 2 started to co-exist. This also meant that the Python 3 code would not run Python 2 and vice-a-versa.\nAccording to PSF, Starting January 1, 2020, the Python 2.x versions will no longer be supported. So, at machinelearningpy.com, we only use Python version 3 or simply Python 3.\nThings to keep in mind There are a few things we should keep in mind while learning the Python programming language.\n Python places a particular emphasis on spacing. So, Spacing is essential. Python is a case sensitive language. That means python and Python are two different objects.  Operators in Python In programming languages, operators are used for performing operations on values, variables, and objects. In Python, we can group these operators into seven groups.\n Comparison Operators Arithmetic Operators Assignment Operators Logical Operators Membership Operators Identity Operators Bitwise Operators  Comparison Operators Python As the same suggests, the operators are used for comparing two values. These can be actual values or values stored inside variables like X and Y.\n   Operator  Name      == Equal   != Not equal   \u0026gt; Greater than   \u0026lt; Less than   \u0026gt;= Greater than or equal to   \u0026lt;= Less than or equal To    Example #1 - Comparison Operators Python 1 2 3 4 5 6 7 8 9 10 11 12 13 14  x = 10\rx == 10\r# Output :- True\r x != 10\r# Output :- True\r x \u0026gt; 10\r# Output :- False\r x \u0026lt; 15\r# Output :- True\r x \u0026gt;+ 10\r# Output :- True\r x \u0026lt;= 15\r# Output :- True\r   Arithmetic Operators Python These operators are used to perform common mathematical operations.\n   Operator  Name      + Addition   - Subtraction   / Division   * Multiplication   % Modulus   ** Exponential   // Floor Division    Example #1 - Arithmetic Operators Python 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  x = 10\ry = 24\rprint(f\u0026#34;Addition: {x + y}\u0026#34;)\r# Output :- Addition: 34\r print(f\u0026#34;Subtraction: {x - y}\u0026#34;)\r# Output :- Subtraction: -14\r print(f\u0026#34;Division: {x / y}\u0026#34;)\r# Output :- Subtraction: 0.4166666666666667\r print(f\u0026#34;Multiplication: {x * y}\u0026#34;)\r# Output :- Multiplication: 240\r print(f\u0026#34;Modulus: {x %y}\u0026#34;)\r# Output :- Modulus: 10\r print(f\u0026#34;Exponential: {x ** y}\u0026#34;)\r# Output :- Exponential: Exponential: 1000000000000000000000000\r print(f\u0026#34;Floor Division: {x // y}\u0026#34;)\r# Output :- Floor Division: 0\r   Python Rules of Precedence Python follows the same rules of precedence as mathematics for its arithmetic operators.\n  The highest precedence among arithmetic operators is given to Exponential.\n  The nest precedence is given to Multiplication and Division operators, which have the same priority.\n  Subtraction and Addition also have the same precedence but are executed only after Multiplication and Division.\n   Operators with the same precedences are evaluated from left to right.\n To force an expression to evaluate as per your want, use parentheses. parentheses have the highest precedence.\nExample #2 - Arithmetic Operators Precendece 1 2 3 4  print(f\u0026#34;Left to right rule: {3 - 2 + 1}\u0026#34;)\r# Output :- As per left to right rule: 2\r print(f\u0026#34;forced calculations: {3 - (2 + 1)}\u0026#34;)\r# Output :- forced calculations: 0\r   Assignment Operators Python These operators are used for assigning values to variables.\n   Operator  Example  Alternative      = x = 3 x = 3   /= x /= 3 x = x / 3   += x += 3 x = x + 3   -= x -= 3 x = x - 3   %= x %= 3 x = x % 3    Example #1 - Assignment Operators Precendece 1 2 3 4 5 6 7 8 9  x = 10\rprint(f\u0026#34;x value is: {x}\u0026#34;)\r# Output :- x value is: 10\r x += 15\rprint(f\u0026#34;Adding 15, x updated value: {x}\u0026#34;)\r# Output :- Adding 15, x updated value: 25\r x %= 3\rprint(f\u0026#34;Remainder: {x}\u0026#34;)\r# Output :- Remainder: 1\r   Logical Operators Python These operators are used to perform everyday mathematical operations.\n   Operator  Details  Example      and Returns True if all statements are True A \u0026gt; 10 and B \u0026lt; 5   or Returns True if one of statements is True A \u0026gt; 10 or B \u0026lt; 5   not Return True if result was False; Reverses the result not(A \u0026gt; 10 and B \u0026lt; 5)    Example #1 - Logical Operators Python 1 2 3 4 5 6 7 8  x = 10\ry = 24\rprint(f\u0026#34;AND logic result: {x \u0026gt; 10 and y \u0026lt; 30}\u0026#34;)\r# Output :- AND logic result: False\r print(f\u0026#34;OR logic result: {x \u0026lt; 10 or y \u0026lt; 30}\u0026#34;)\r# Output :- OR logic result: True\r print(f\u0026#34;NOT logic result: {not(x \u0026lt; 10 or y \u0026lt; 30)}\u0026#34;)\r# Output :- NOT logic result: False\r   Membership Operators Python Python membership operators are used to check if a value or sequence is present in another object.\n   Operator  Details      in True is returned if value is present   not in True is returned if value is not present    Example #1 - Membership Operators Python 1 2 3 4 5 6  x = [10, 20, 23, 40, 76, 11]\ry = 24\rprint(f\u0026#34;in membership operator result: {y in x}\u0026#34;)\r# Output :- in membership operator result: False\r print(f\u0026#34;not in logic result: {y not in x}\u0026#34;)\r# Output :- not in membership operator result: True\r   Identity Operators Python Identity operators are used for comparing two objects. They check if the objects/variables are exactly the same or not. The same entities share the same memory location.\n   Operator  Details      is True is returned if objects are same   is not True is returned if objects are not same    Example #1 - Identity Operators Python 1 2 3 4 5 6  x = 24\ry = 24\rprint(f\u0026#34;is membership operator result: {y is x}\u0026#34;)\r# Output :- is membership operator result: True\r print(f\u0026#34;is not membership operator result: {y is not x}\u0026#34;)\r# Output :- is not membership operator result: False\r   Bitwise Operators Python In Python, one can use bitwise operators to compare the binary numbers. As a data scientist, I have not used these operators. However, if you are interested - Click Here\nData Types in Python Below is the list of data types python supports. Examples of each type are also provided. In this section, we will look at some of the important functions and methods which will help you identify the data type of a variable in Python.\n integer (int) - Example: 1, 2, 3 float (float) - Example: 1.23, 0.23 boolean (bool) - Example: True, False string (str) - Example: \u0026ldquo;Mohit\u0026rdquo; , \u0026ldquo;Python Champions\u0026rdquo;  type() Check Python Data Type 1 2 3 4 5 6 7 8 9 10 11 12  w = 14\rprint(type(w))\r# Output :- int\r x = \u0026#34;Machine Learning\u0026#34;\rprint(type(x))\r# Output :- str\r y = 3.14\rprint(type(y))\r# Output :- float\r z = True\rprint(type(z))\r# Output :- bool\r   Defining Strings in Python To define a string in one single line one can use single ' or double \u0026quot; quotes.\n1 2  str_ex1 = \u0026#34;This is an exmple string\u0026#34;\rstr_ex2 = \u0026#39;This is also an exmple string\u0026#39;\r  If your string contains one of these symbols as part of raw text then you can include those by using \\ in your string.\n1 2 3 4 5 6 7 8 9 10  str_ex3 = \u0026#39;Bob\u0026#39;s father is a builder.\u0026#39; print(str_ex3)\r# Output :- File \u0026#34;\u0026lt;ipython-input-47-73cfef63c547\u0026gt;\u0026#34;, line 1\r # str_ex4 = \u0026#39;Bob\u0026#39;s father is a builder.\u0026#39;\r # ^\r #SyntaxError: invalid syntax\r str_ex4 = \u0026#39;Bob\\\u0026#39;s father is a builder.\u0026#39;\rprint(str_ex4)\r# Output :- Bob\u0026#39;s father is a builder.\r   Another way around is to use double \u0026quot; if you have single ' quote inside your string or vice-a-versa.\n1 2 3  str_ex5 = \u0026#34;Bob\u0026#39;s father is a builder.\u0026#34;\rprint(str_ex5)\r# Output :- Bob\u0026#39;s father is a builder.\r   Arithmetic Functions on Strings Some arithmetic functions can be applied on strings. For example -\n + operator can be used to concatinate two strings.  1 2 3 4  str_ex6 = \u0026#34;Hello\u0026#34;\rstr_ex7 = \u0026#34;Reader\u0026#34;\rprint(str_ex6 + str_ex7)\r# Output :- HelloReader\r   Notice no spacing is provided. We shall manually provide a blank space in order to make ki more readable.\n1 2 3 4  str_ex6 = \u0026#34;Hello\u0026#34;\rstr_ex7 = \u0026#34;Reader\u0026#34;\rprint(str_ex6 + \u0026#34;, \u0026#34; + str_ex7)\r# Output :- Hello, Reader\r    We can use * to replicate the string multiple number of times.  1 2 3  str_ex8 = \u0026#34;Apple\u0026#34;\rprint(str_ex8 * 2)\r# Output :- AppleApple\r   len() get length of an object The len() function in Python returns total length of an object. We can use it to get the number of character in a string.\n1 2 3  str_ex8 = \u0026#34;Apple\u0026#34;\rprint(f\u0026#34;Total number of character in string are {len(str_ex8)}\u0026#34;)\r# Output :- Total number of character in string are 5\r   Methods in Python Until now we have seen three functions like print(), type() and len(). A function in Python uses parentheses and can accept one or more arguments. In the coming lessons, we will study them in detail.\nA method in Python is a built-in function. They are very similar to any other Python function and are called using dot notation. For example, upper() is a string method that can be used to convert all the characters of a string to upper case: str_ex8.upper() to get \u0026lsquo;APPLE\u0026rsquo;.\nTop 10 String Methods in Python Some of the important strings methods are listed below:\n   Method Name  Details      lower() converts string to lower case   islower() Returns True if all characters are in lower case   uper() converts string to upper case   isupper() Returns True if all characters are in upper case   strip() Returns trimmed strings   split() Splits string by a specified separator, and returns a list   format() Formats the string   count() Counts the numer of times a specified value occurs in a string   endswith() Returns True if string ends with specified value   startswith() Returns True if string starts with specified value    Example #1 - Top 10 String Methods Python 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  str_method_ex1 = \u0026#34;This is an ARTICLE from machine learning py blog.\u0026#34;\rprint(\u0026#34;string to lower:{} \u0026#34;.format(str_method_ex1.lower()))\r# Output :- string to lower: this is an article from machine learning py blog.\r print(\u0026#34;Is string in lower:{} \u0026#34;.format(str_method_ex1.islower()))\r# Output :- Checking if string in lower:False  print(\u0026#34;string to upper:{} \u0026#34;.format(str_method_ex1.upper()))\r# Output :- string to upper: THIS IS AN ARTICLE FROM MACHINE LEARNING PY BLOG.\r str_method_ex2 = \u0026#34;ALL TEXT IN CAPS\u0026#34;\rprint(\u0026#34;Is string in upper:{} \u0026#34;.format(str_method_ex2.isupper()))\r# Output :- Is string in upper:True\r str_method_ex3 = \u0026#34;I have trailing and leadning white spaces \u0026#34;\rprint(\u0026#34;Striping whitespace:{} \u0026#34;.format(str_method_ex3.strip()))\r# Output :- Striping whitespace: I have trailing and leadning white spaces\r print(\u0026#34;splitting string by space:{} \u0026#34;.format(str_method_ex2.split(\u0026#34;\u0026#34;)))\r# Output :- splitting string by space:[\u0026#39;ALL\u0026#39;, \u0026#39;TEXT\u0026#39;, \u0026#39;IN\u0026#39;, \u0026#39;CAPS\u0026#39;]  str_method_ex4 = \u0026#34;There are couple of apples and I ate some of these apples\u0026#34;\rprint(\u0026#34;Count of string apples:{} \u0026#34;.format(str_method_ex4.count(\u0026#34;apples\u0026#34;)))\r# Output :- Count of string apples:2  print(\u0026#34;Does string ends with apples:{} \u0026#34;.format(str_method_ex4.endswith(\u0026#34;apples\u0026#34;)))\r# Output :- Does string ends with apples: True\r print(\u0026#34;Does string ends with apples:{} \u0026#34;.format(str_method_ex4.startswith(\u0026#34;apples\u0026#34;)))\r# Output :- Does string ends with apples: False\r   Data Structures in Python Data Structures can be thought of as a container. These containers are required to organize and store different data types. These containers or structures can be defined based upon the dimension or based upon there ability to store different types of data. In Python, we have the following types of Data Structures.\n Lists Tuples Sets Dictionaries Compound Structure  While you work on these data structures, you shall also keep in mind the following:\n Is data structure Mutable? Is data structure Ordered?  Mutability here refers to whether you can change the elements of a data structure. If you can modify the data structure is called Mutable else, it is called immutable.\nOrdered refers to whether you can access the elements stored in a data structure using their position. If you can, then the data structure is called as ordered. If not, it is called as unordered.\nLists in Python A list is a fundamental data structure in Python. It is also one of the most commonly used data structures. A list can contain a mix of different data types. You can create a list using the square [] brackets.\n1  list_ex1 = [12, 13.13, \u0026#34;Python\u0026#34;, True]\r  list_ex1 is a list containing four elements. All the elements in the list can be accessed using an index. The indexing value starts at 0, which is assigned to the first element. Alternatively, lists are also indexed from the end using -1. Thus, you can pull out 12 by referring to the index 0 and last element True by referring to -1.\n1 2 3 4 5 6 7 8  list_ex1[0]\r# Output :- 12\r list_ex1[3]\r# Output :- True\r list_ex1[-1]\r# Output :- True\r list_ex1[len(list_ex1) - 1]\r# Output :- True\r   Slicing and Dicing List Slicing refers to the extraction of more than one value from a data structure. The below example shows how you can extract more than one value from the list.\n Return first three elements  1 2  list_ex1[0:3]\r# Output :- [12, 13.13, \u0026#39;Python\u0026#39;]\r   Notice, the lower index is inclusive and the upper index is exclusive.\nReturn all elements starting specified index  1 2  list_ex1[2 : ]\r# Output :- [\u0026#39;Python\u0026#39;, True]\r   Replace value at specified index  1 2 3  list_ex1[2] = 33\rlist_ex1\r# Output :- [12, 13.13, 33, True]\r   Replace more than one value in list  1 2 3  list_ex1[0,4] = [99, 120]\rlist_ex1\r# Output :- [99, 13.13, 33, 120]\r    A list is both mutable and ordered.\n  A string, on the other hand, is immutable. You can not change a character in a string without creating a new string.\n 1 2  string_ex1 = \u0026#34;Strings are immutable\u0026#34;\rstring_ex1[0] = \u0026#34;G\u0026#34;\r  Top 11 List Methods in Python Some of the important strings methods are listed below:\n   Method Name  Details      apend() Inserts an element at the end   clear() Deletes all the elements from the list   insert() Inserts element at a specific index   pop() Remove element from the specific place   remove() removes the first occurance of specified value in a list   sort() Sorts the list in arranging and descending order   reverse() order of list is reserved   copy() creates and returns the copy of list   index() For a specified value returns the index   extend() joins the elements of a list, to the end of the current list   join() returns a string consisting of the list elements joined by a separator    Example #1 - Top 11 String Methods Python 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  ls_method_ex1 = [12, 34, 1, 15, 66, 54]\rls_method_ex1.append(99)\rls_method_ex1\r# Output :- [12, 34, 1, 15, 66, 54]\r ls_method_ex1.clear()\rls_method_ex1\r# Output :- []\r ls_method_ex2 = [12, 34, 1, 15, 66, 54]\rls_method_ex2.insert(2, 99)\rls_method_ex2\r# Output :- [12, 34, 99, 1, 15, 66, 54]\r ls_method_ex2.pop(2, 99)\rls_method_ex2\r# Output :- [12, 34, 1, 15, 66, 54]\r ls_method_ex3 = [12, 34, 1, 15, 66, 54, 12]\rls_method_ex3.remove(12)\rls_method_ex3\r# Output :- [34, 1, 15, 66, 54, 12]\r ls_method_ex3.sort()\rls_method_ex3\r# Output :- [1, 12, 12, 15, 34, 54, 66]\r ls_method_ex3.reverse()\rls_method_ex3\r# Output :- [66, 54, 34, 15, 12, 12, 1]\r ls_method_ex3.index(1)\rls_method_ex3\r# Output :- 6\r ls_method_ex3.extend([2,3,4])\rls_method_ex3\r# Output :- [66, 54, 34, 15, 12, 12, 1, 2, 3, 4]\r ls_method_ex4 = [\u0026#34;Machine\u0026#34;, \u0026#34;Learning\u0026#34;, \u0026#34;Python\u0026#34;, \u0026#34;Programming\u0026#34;, \u0026#34;Blog\u0026#34;]\r(\u0026#34;+ \u0026#34;).join(ls_method_ex4)\rls_method_ex4\r# Output :- \u0026#39;Machine + Learning + Python + Programming + Blog\u0026#39;\r   Example #2 - Top 4 Handy Functions for Lists in Python  len() - Returns the count of elements in a list.  1 2  len([1,2,3,4,5,6,7,8,9,10])\r# Output :- 10\r   min() - Returns the min value inside a list.  1 2  min([1,2,3,4,5,6,7,8,9,10])\r# Output :- 1\r   max() - Returns the maximum value inside a list.  1 2  max([1,2,3,4,5,6,7,8,9,10])\r# Output :- 10\r   sorted() - Returns the maximum value inside a list.  1 2  sorted([11,2,32,14,59,61,7,18,90,10])\r# Output :- [2, 7, 10, 11, 14, 18, 32, 59, 61, 90]\r   Tuples in Python Tuple is a useful data structure in Python. Unlike list they are immutable but are ordered container. That means once a tuple is defined, you cannot change the values of this data structure. Sorting of elements inside tuples is not possible. Often, you will use tuples to store a related piece of information. For example, you can use them to store country names and currency names, or you can use them to store information about latitude and longitude.\n How to define a tuple - A tuple can be defined using a parentheses. However, it not necessary to use parentheses.  1  curreny = (\u0026#34;India\u0026#34;, \u0026#34;INR\u0026#34;)\r  Extracting values from a tuple  1 2  curreny[0]\r# Output :- India\r   Assigning multiple variable - Tuples are very useful for assigning multiple variable in a compact way.  1 2 3  length, width = 12, 4\rprint(f\u0026#34;The dimensions are {length} x {width}\u0026#34;)\r# Output :- The dimensions are 12 x 4\r   Tuple Methods in Python    Method Name  Details      count() returns the count of specific value   index() returns the index of specified value    Example #1 - Tuple Methods in Python 1 2 3 4 5 6  tuple_method_ex1 = 12, 12, 1, 66, 66, 66\rtuple_method_ex1.count(66)\r# Output :- 3\r tuple_method_ex2 = (\u0026#34;cat\u0026#34;, \u0026#34;dog\u0026#34;, \u0026#34;mice\u0026#34;, \u0026#34;rabbit\u0026#34;)\rtuple_method_ex2.index(\u0026#34;mice\u0026#34;)\r# Output :- 2\r   Sets in Python Set is a data structure that is mutable and unordered. Mostly, Python programmers use it swiftly remove the duplicates for a list. Others use it for set operations. For example, looking for differences, intersections, and unions are mostly done using sets.\n ** Defining a Set in Python** - To define a **set** you can use set function.  1 2 3  set_ex1 = set([1,1,2,3,3,4,4,5,6,9,9,9])\rset_ex1\r# Output :- {1, 2, 3, 4, 5, 6, 9}\r    Some of the list methods can be used with sets. For example, you can add elements to the tuple using add method or you can use pop method to remove an element. However, it is not recommended to use pop as a random element is removed. Remember sets are undordered.\n Top 5 Set Methods in Python    Method Name  Details      add() Inserts an element   difference() Provides a set with a difference between 2 or more sets   update() Updates the set with the union of other set   intersection() Provides a set with common elements between 2 or more sets   union() Returns a set containing union of sets.    Example #1 - Top 5 Set Methods in Python 1 2 3 4 5 6 7 8 9 10 11 12 13 14  set_ex2 = set([1,2,3,4,5,6,7,8,9,10])\rset_ex2.add(11)\rset_ex2\r# Output :- {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}\r set_ex3 = set([3,5,7,8,10])\rset_ex2.difference(set_ex3)\r# Output :- {1, 2, 4, 6, 9, 11}\r set_ex2.update(set([22,33,44]))\rset_ex2\r# Output :- {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 22, 33, 44}\r set_ex2.intersection(set_ex3)\r# Output :- {3, 5, 7, 8, 10}\r set_ex2.union(set_ex3)\r# Output :- {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 22, 33, 44}\r   Dictionaries in Python Dictionaries are interesting data structures. They store values by mapping them to a unique key. A dictionary is a mutable data structure. However, the keys of the data structure can be of any immutable type like tuples or integers.\n Keys in the dictionary do not necessarily require to have the same type!\n  Defining a dictionary in Python - There are two ways to define a dictionary. One, you can use a dict() function, and second, you can use curly braces {}.  1  dict_ex1 = {\u0026#34;apple\u0026#34;: 100, \u0026#34;bannana\u0026#34;: 70, \u0026#34;orange\u0026#34;: 120}\r  Printing the values of a specific key - You can use square [] brackets enclosing the key for which you need to access the value.  1 2  dict_ex1[\u0026#34;apple\u0026#34;]\r# Output :- 100    Re-assign the values of a specific key  1 2 3  dict_ex1[\u0026#34;apple\u0026#34;] = 150\rdict_ex1[\u0026#34;apple\u0026#34;]\r# Output :- 150\r   Check if a key exists in dictionary - You can use in identity  1 2 3 4  print(\u0026#34;orange\u0026#34; in dict_ex1)\r# Output :- True\r print(\u0026#34;mango\u0026#34; in dict_ex1)\r# Output :- False\r    Values associated with keys can be a single value, a list, a tuple, or could be a dictionary in itself.\n Top 5 Dictionary Methods in Python    Method Name  Details      get() Returns the value associated with specified key   items() Returns a list containing a tuple for each key value pair   keys() Returns keys from a dictionary   values() Returns all the values as list from dictionary   fromkeys() Returns a dictionary with specific key and value    Example #1 - Top 5 Dictionary Methods in Python 1 2 3 4 5 6 7 8 9  dict_ex2 = {\u0026#34;apple\u0026#34;: 100, \u0026#34;banana\u0026#34;: 70, \u0026#34;orange\u0026#34;: 120, \u0026#34;mango\u0026#34;: 200}\rdict_ex2.get(\u0026#34;mango\u0026#34;)\r# Output :- 200\r dict_ex2.items()\r# Output :- dict_items([(\u0026#39;apple\u0026#39;, 100), (\u0026#39;banana\u0026#39;, 70), (\u0026#39;orange\u0026#39;, 120), (\u0026#39;mango\u0026#39;, 200)])\r dict_ex2.keys()\r# Output :- dict_keys([\u0026#39;apple\u0026#39;, \u0026#39;banana\u0026#39;, \u0026#39;orange\u0026#39;, \u0026#39;mango\u0026#39;])\r dict_ex2.values()\r# Output :- dict_values([100, 70, 120, 200])\r   Compound Structures Compound Strutures come into existence when we include a data structure inside another data structure. For example, nested dictionaries which contains dictionary inside a dictionary fall under compound structures.\n1 2 3 4 5 6 7 8  nutrition = {\u0026#34;apple\u0026#34;: {\u0026#34;kcal\u0026#34;: 52,\r\u0026#34;protein\u0026#34;: 0.83,\r\u0026#34;carbs\u0026#34;: 13.8,\r\u0026#34;fat\u0026#34;: 0.2},\r\u0026#34;banana\u0026#34;: {\u0026#34;kcal\u0026#34;: 89,\r\u0026#34;protein\u0026#34;: 1.1,\r\u0026#34;carbs\u0026#34;: 23,\r\u0026#34;fat\u0026#34;: 0.3}}\r  Elements inside the above-nested dictionary are accessed in the same fashion as we do for regular dictionaries.\n1 2 3  apple = nutrition[\u0026#34;apple\u0026#34;]\rapple\r# Output :- {\u0026#39;carbs\u0026#39;: 13.8, \u0026#39;fat\u0026#39;: 0.2, \u0026#39;kcal\u0026#39;: 52, \u0026#39;protein\u0026#39;: 0.83}\r   You can see that we got the inner dictionary and now we can get values for any of the keys. For example, protein content can be extracted using the following code.\n1 2 3  protein = apple[\u0026#34;protein\u0026#34;]\rprotein\r# Output :- 0.83\r   To access the values directly you can also follow the below code.\n1 2  nutrition[\u0026#34;apple\u0026#34;][\u0026#34;protein\u0026#34;]\r# Output :- 0.83\r   Building Logic to your Python Code To be a programmer is nothing more than guiding the steps your program should take when encountered with different values. It is like setting up the flow of your code, and that can only be achieved through clearly defining and building logic into your code. In this section, you will learn about tools that will help you make this logic work.\nThe logic building tools can be further divided into the following.\n Conditional Statements While and For Loops Break and Continue   Comparision and Logical statements are extensively used while building logic to your code.\n Conditional Statements Python As part of Conditional Statements, Python provides the following two options.\nIF Statement An if statement is executed if the condition is met. Otherwise, no action is taken. Please pay close attention to the indentation.\n1 2 3  x = 20\rif x \u0026gt; 10:\rprint(x)\r  One line Representation\n1 2  x = 20\rif x \u0026gt; 10: print(x)\r  IF, Elif, ELSE Sometimes you may also want to take action if the condition is not met(it's a good practice use else). At other times you may be interested in checking multiple conditions, and based on each one, a different action is required.\n1 2 3 4 5 6 7 8  x = 20\ry = 30\rif x \u0026gt; y:\rprint(x/y)\relif x \u0026lt; y:\rprint((x + y)/y)\relse:\rprint(\u0026#34;The two numbers are equal\u0026#34;)\r  If.. Else. One line Representation\n1 2 3  x = 20\ry = 30\rprint(x/y) if x \u0026gt; y else print(\u0026#34;The x is less than y.\u0026#34;)\r  While loop Python while loop is an example of indefinite iteration, that means the loop will repeat an unknown number of times and will only stop when it meets a certain condition. For example, we will move the last ten elements from numbers to a new list until the count reaches 10.\n1 2 3 4 5  numbers = list(range(1, 20))\rnew_list = []\rwhile len(new_list) \u0026lt;= 10:\rnew_list.append(numbers.pop())\r  For loop Python for loop is an example of a definitive iteration. It is used to do something repeatedly using an iterable. An iterable is an object that can return one value at a time, such as a list, tuples, dictionaries, and files.\n1 2 3 4  country_names = [\u0026#34;United States of America\u0026#34;, \u0026#34;Canada\u0026#34;, \u0026#34;Mexico\u0026#34;, \u0026#34;Spain\u0026#34;, \u0026#34;Chile\u0026#34;]\rfor i in country_names:\rprint(i)\r  1 2 3 4 5 6  # Output\rUnited States of America\rCanada\rMexico\rSpain\rChile\r  The i variable is called an iterable variable. You can name it whatever you like. It's not necessary to call it i always. A good practice is to give the same names to both the iterable and iteration variable.\nExample #1 - For loop with tuples 1 2 3 4  country_names = (\u0026#34;United States of America\u0026#34;, \u0026#34;Canada\u0026#34;, \u0026#34;Mexico\u0026#34;, \u0026#34;Spain\u0026#34;, \u0026#34;Chile\u0026#34;)\rfor country in country_names:\rprint(country)\r  Example #2 - For loops for iterating through dictionaries for loops when used with dictionaries only return the keys.\n1 2 3 4 5 6 7 8 9 10 11  nutrition = {\u0026#34;apple\u0026#34;: 52,\r\u0026#34;lemon\u0026#34;: 0.83,\r\u0026#34;mango\u0026#34;: 13.8,\r\u0026#34;egg\u0026#34;: 0.2,\r\u0026#34;banana\u0026#34;: 89,\r\u0026#34;milk\u0026#34;: 1.1,\r\u0026#34;beacon\u0026#34;: 23,\r\u0026#34;meat\u0026#34;: 0.3}\rfor food in nutrition:\rprint(food)\r  1 2 3 4 5 6 7 8 9  # Output\rapple\rlemon\rmango\regg\rbanana\rmilk\rbeacon\rmeat\r  To iterate over both keys and values, you can use items() method as given below.\n1 2 3 4 5 6 7 8 9 10 11  nutrition = {\u0026#34;apple\u0026#34;: 52,\r\u0026#34;lemon\u0026#34;: 0.83,\r\u0026#34;mango\u0026#34;: 13.8,\r\u0026#34;egg\u0026#34;: 0.2,\r\u0026#34;banana\u0026#34;: 89,\r\u0026#34;milk\u0026#34;: 1.1,\r\u0026#34;beacon\u0026#34;: 23,\r\u0026#34;meat\u0026#34;: 0.3}\rfor key, value in nutrition.items():\rprint(f\u0026#34;Food Name: {key}, Nutrition Value: {value} \u0026#34;)\r  1 2 3 4 5 6 7 8 9  # Output\rFood Name: apple, Nutrition Value: 52 Food Name: lemon, Nutrition Value: 0.83 Food Name: mango, Nutrition Value: 13.8 Food Name: egg, Nutrition Value: 0.2 Food Name: banana, Nutrition Value: 89 Food Name: milk, Nutrition Value: 1.1 Food Name: beacon, Nutrition Value: 23 Food Name: meat, Nutrition Value: 0.3   Break and Continue in Python Many times your logic will require the iteration to end or skip a value when a specific condition is met. In such cases, keywords like break and continue will help you out.\n break can terminate a loop as soon as a specific condition is met.  1 2 3 4  for i in list(range(0, 20)):\rif i == 7:\rbreak\rprint(i)\r  1 2 3 4 5 6 7 8  # Output\r0\r1\r2\r3\r4\r5\r6\r   continue is used to skip an iterable value when a specific condition is met.  1 2 3 4  for i in list(range(0, 10)):\rif i == 7:\rcontinue\rprint(i)\r  1 2 3 4 5 6 7 8 9 10 11  # Output\r0\r1\r2\r3\r4\r5\r6\r8\r9\r10\r  Bonus - Zip and Enumerate Python While working with loops you will find zip and enumerate very useful.\nzip function in python zip is used to combine multiple iterables into tuples. Each tuple contains the combination of elements by position. For example, We have two lists - 1. names as [\u0026ldquo;Bob\u0026rdquo;, \u0026ldquo;Roxana\u0026rdquo;, \u0026ldquo;Charlie\u0026rdquo;, \u0026ldquo;Tango\u0026rdquo;]. 2. weights as [120, 90, 80, 100].\nwe can use zip function to return an iterator combining name and weights values like - [(\u0026lsquo;Bob\u0026rsquo;, 120), (\u0026lsquo;Roxana\u0026rsquo;, 90), (\u0026lsquo;Charlie\u0026rsquo;, 80), (\u0026lsquo;Tango\u0026rsquo;, 100)].\n1 2 3 4 5  names = [\u0026#34;Bob\u0026#34;, \u0026#34;Roxana\u0026#34;, \u0026#34;Charlie\u0026#34;, \u0026#34;Tango\u0026#34;]\rweights = [120, 90, 80, 100]\rfor name, weight in zip(names, weights):\rprint(f\u0026#34;Name is {name}, and Weight is {weight}\u0026#34;)\r  1 2 3 4 5  # Output\rName is Bob, and Weight is 120\rName is Roxana, and Weight is 90\rName is Charlie, and Weight is 80\rName is Tango, and Weight is 100\r  enumerate function in python enumerate function is somewhat similar to zip function. However, instead of combining two different iterables, the function combines an iterable with the indices.\n1 2 3 4  names = [\u0026#34;Bob\u0026#34;, \u0026#34;Roxana\u0026#34;, \u0026#34;Charlie\u0026#34;, \u0026#34;Tango\u0026#34;]\rfor name in enumerate(names):\rprint(name)\r  1 2 3 4 5  # Output\r(0, \u0026#39;Bob\u0026#39;)\r(1, \u0026#39;Roxana\u0026#39;)\r(2, \u0026#39;Charlie\u0026#39;)\r(3, \u0026#39;Tango\u0026#39;)\r  Functions in Python A function is a way of wrapping a specific task related code into some container so that one can use it repeatedly without writing those multiple lines of code again and again.\nFor example - the below function returns the whole square of A + B using the following formula.\n(a + b)^2 = a^2 + b^2 + 2ab\nExample #1 Defining Functions 1 2 3 4 5  def whole_square(a = 1, b = 1):\rreturn((a*a) + (b*b) + 2*a*b)\rwhole_square(4, 6)\r# Output :- 100\r   A function definition includes the following important parts.\n The def keyword - It indicates it is a function. Function name - This is the name of the function. Arguments - A function can have as many arguments as possible. All arguments are passed as inputs to the function and are used with the function call. You need to mention them inside the parentheses.  Note- it is not necessary to pass arguments one can write a function without inputs.\n Body - The block of code after the : is referred to as a body. You can refer to the argument variables or can define new variables inside the body.\n  return - The body often ends with the return statement. The keyword is followed by an expression that is evaluated to get the output. The function with no return statement returns None.\n  Example #2 Anonymous Functions Python A lambda expression can be used to define an anonymous function in Python. This function is called anonymous because there is no name. You can use lambda function if you don't need them again and again.\nThe above whole_square function can be reduced to lambda function as given below:\n1 2  whole_square = lambda x, y: x * x + y * y + 2*x*y\rwhole_square(4,6)\r  Example #3 Documentation Strings in Python To ensure that your function is readable, it is important that you provide documentation of your code. Documented code is easier to use and understand. Python provides docstrings specifically for documentation purposes.\nA docstring or document string is nothing more than a comment which is mentioned using Tripple \u0026quot;\u0026quot;\u0026quot;.\n1 2 3 4 5 6 7 8 9  def whole_square(a = 1, b = 1):\r\u0026#34;\u0026#34;\u0026#34;Calculate the whole square of A + B.\rINPUT:\ra: int value\rb: int value\rOUTPUT:\ra^2 + b^2 + 2*a*b\r\u0026#34;\u0026#34;\u0026#34;\rreturn((a*a) + (b*b) + 2*a*b)\r   You can also include examples into the document string.\n Errors and Exceptions in Python As a programmer, one is likely to make mistakes. These mistakes in Python can be categorized as either Errors or Exception.\n  Errors - These occur when Python is not able to interpret your code due to syntax related issues. Mostly, typos are the reasons for such errors. For this reason, they are also referred to as Syntax Errors.\n  Exceptions - Even if your code is syntactically correct, some unexpected things can prevent your code from executing. All such cases fall under exceptions. Python provides a collection of different in-built exceptions. They help in understanding the underlying problem, which is preventing code from executing.\n  As Errors and Exceptions are not good, you need to understand how to handle them.\nHandling Errors and Exceptions Python To handle exceptions in Python, you can make use of the try statement. The try statement evaluates a block of code, and if it encounters an exception, it jumps to the except block. We can also mention what should happen if no exception is found in the else block. Finally, after executing the try, else or  except blocks, the code runs the final block called finally.\n1 2 3 4 5 6 7 8 9 10 11 12  x = int(12)\rwhile True:\rtry:\rif isinstance(x, int):\rprint(x)\rexcept ValueError:\rprint(\u0026#34;x is not an integer\u0026#34;)\relse:\rx += 1\rprint(f\u0026#34;printing updated {x}\u0026#34;) finally:\rprint(\u0026#34;This is an example covering all the block\u0026#34;)\r  1 2 3 4  #Output\r12\r13\rThis is an example covering all the block\r  In the above example, the try statement is only going to look for ValueError and will ignore others. If you wish to catch multiple exceptions, then you can pick any of the below mentioned coding styles.\n1 2 3 4 5 6 7  x = int(12)\rwhile True:\rtry:\rif isinstance(x, int):\rprint(x)\rexcept (ValueError, ZeroDivisionError):\rprint(\u0026#34;We found errors\u0026#34;)\r  1 2 3 4 5 6 7 8 9  x = int(12)\rwhile True:\rtry:\rif isinstance(x, int):\rprint(x)\rexcept ValueError:\rprint(\u0026#34;We found Value Errors\u0026#34;)\rexcept ZeroDivisionError:\rprint(\u0026#34;We found ZeroDivisionError\u0026#34;)\r  Capturing and Accessing Error Messages Most exceptions come with the error messages. That means one can access these error messages and print them on the console for straightforward interpretation by users.\n1 2 3 4 5 6 7 8  x = 12\ry = 0\rtry:\rz = x/y\rexcept ZeroDivisionError as e:\rprint(\u0026#34;Error Occurred: {}\u0026#34;.format(e))\r# Output :- Error Occurred: division by zero\r    Even if you don't have an idea about the kind of error, you can still capture the error message.\n 1 2 3 4 5 6 7 8  x = 12\ry = 0\rtry:\rz = x/y\rexcept Exception as e:\rprint(\u0026#34;Error Occurred: {}\u0026#34;.format(e))\r# Output :- Error Occurred: division by zero\r   Reading and Writing Files in Python To read a file in Python, you need to open it by using the open built-in function. You can provide some arguments like read-only, write-only, or read and write. Once that is done, you can use a read() method to read the contents of the file.\nOnce finished with the file reading, you should close it using close() built-in function.\nExample #1 Reading Text File Python 1 2 3  file = open(\u0026#34;/data/MartinLutherKing.txt\u0026#34;, \u0026#39;r\u0026#39;)\rdream_speech = file.read()\rfile.close()\r  Example #2 Writing Text File Python The steps involved in writing the text file are also very similar.\n You need to open the file in writing mode. If the file does not exist, don't worry, Python will create one for you. Use a writing mode to write the content to the file. Close the connection.  1 2 3  file = open(\u0026#34;/data/speech_copy.txt\u0026#34;, \u0026#39;w\u0026#39;)\rfile.write()\rfile.close()\r  Example #3 Auto closing the opened files You can use with function to auto-close the opened files after the reading or writing step is completed.\n1 2  with open(\u0026#39;/data/MartinLutherKing.txt\u0026#39;, \u0026#39;r\u0026#39;) as file:\rdream_speech = file.read()\r  Loading Local and Third-Party Libraries Python comes with many useful built-in functions and methods. There are also a huge number of third-party libraries. These libraries need to be installed and loaded into your session to access the specific functions.\nYou can also load local scripts into your current session. This is mostly required while working on larger projects. For larger projects, it is advised to split your code into multiple scripts to organize them better. For example, one can list all user-defined functions in one script.\nExample #1 Importing Local Scripts Python If the current script and the script you wish to load are in the same folder, then you can use import followed by the script name to load the contents of the script.\n1  import project_functions_list\r  If the script name is too big, as in the above case, we can also provide an alias to it by use as.\n1  import project_functions_list as pft\r  Example #2 Importing Third Party libraries There are thousands of third-party libraries written by individuals. To install these libraries, you can pip a package manager for Python 3. pip is the standard package manager for the Python, but it is not the only one. For example, Anaconda, which is specifically designed fordata science, has its own package manager named conda.\n To install packages - pip install package_name To install packages from Jupiter notebook - ! pip install package_name.  Example #3 Function Calling Using dot notation To call a function from a package/module, you can use dot notation. For example, below, we call sum() function from numpy package in Python to get the total sum of elements in a list.\n1 2 3  import numpy as np\rnp.sum([22,123,65, 9, 12])\r# Output : - 231\r   Useful Online Resources   Python Tutorial By Google: it is a free class offered by google for people with a little bit of programming experience.\n  Official Python Tutorial: The site provides examples, and is written using less technical language compared to main Python site.\n  Third-Party Library Documentation: Read the Docs is a huge resource that millions of developers rely on for software documentation of thrid parties. Easy to read and consume, I love this site.\n  Best Practice: It is best to define variables in the limited scope based upon the usage. It is rarely a good idea to define a function that can refer to a variable with a broader scope. As your code gets complicated, you may not remember or know what all variables you have defined.\nPlease leave comments, if\n You find anything incorrect. You want to add more information to the topic. You wish to add another example to the topic. You need more details in regards to a specific section. You are unable to execute an example code. "
},
{
	"uri": "/tags/seaborn/",
	"title": "Seaborn",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/tutorial/",
	"title": "Tutorial",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories/visualization/",
	"title": "Visualization",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "/about/",
	"title": "About",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "about page",
	"content": " YOU DON’T HAVE TO BE GREAT TO START, BUT YOU HAVE TO START TO BE GREAT. –ZIG ZIGLAR\n Namaste 🙏,\nWelcome to Machine Learning Blog - A place where you will find articles/tutorials related to machine learning(ML) with Python. The intention is to build an online resource that can serve as a knowledge base for aspiring learners.\nMy name is Mohit Sharma, a seasoned Data Scientist who specializes in advance analytics, machine learning, and deep learning algorithms. I am also a passionate trainer and have trained around 700+ students through both online and offline platforms.\n Through this blog, I wish to share my learning with those who are interested in exploring data science or are looking out to further their knowledge of machine learning algorithms and tools.\n I understand it can be challenging, especially for beginners. When I was starting, I remember I spent sleepless nights studying for around 8 hours after my office and did so for about nine long months that too, with my 10 to 8 job and no work from home. Everything was so confusing and challenging.\nWell, honestly, I was lucky the industry was new, and topics to explore were less as compared to today. However, the scenario has changed, and today an individual is required to know so many things. Through my own experience and from the feedback of my students, I understand this is a very very difficult situation. Most of us struggle with the following questions:\n How much math shall I dig into at the beginning of the data science career? Is math essential for me to standout? Which algorithms shall I learn and how to build one's career from there? Where to get challenging enough dataset to solve a problem? How to handle interview questions? What are the different roles within a data science domain?  If you have these questions, then I request you to bookmark this blog. My aim through this blog is to help you gain as much knowledge as possible through simple and easy to understand theory and at times, mathematical formulas.\nI am not a native English speaker and am also new to blogging. So, I may make some grammatical or spelling mistakes. If you happen to catch such an error, I request you to write back to me with suggestions or feedback. Even if you want to reach out to me for any other reason like a consultation or you are looking for personal training, or if you wish to catch up over a coffee, feel free to write back to me at datasciencebeginners@gmail.com.\n LEARNING IS NOT ATTAINED BY CHANCE, IT MUST BE SOUGHT FOR WITH ARDOR AND ATTENDED TO WITH DILIGENCE. ― ABIGAIL ADAMS\n Happy Learning 👍\nMohit Sharma\n"
},
{
	"uri": "/archive/",
	"title": "Archive",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "Archive Page",
	"content": "archive page\n"
},
{
	"uri": "/series/",
	"title": "Series",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
}]